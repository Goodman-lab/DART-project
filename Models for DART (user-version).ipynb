{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2829af1a",
   "metadata": {},
   "source": [
    "# Installation of required packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e7995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The versions are important otherwise the package dependencies will likely fail\n",
    "print('\\nINSTALLING REQUIRED PACKAGES...')\n",
    "!pip install --upgrade pip==21.1.3\n",
    "\n",
    "!pip install --upgrade setuptools==59.5.0\n",
    "# CPU version of pytorch has smaller footprint - see installation instructions in\n",
    "# pytorch documentation - https://pytorch.org/get-started/locally/\n",
    "#!python -m pip install mitmproxy\n",
    "#!pip install torch==1.10.1+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "!pip install torch==1.10.2 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "\n",
    "# AutoGluon(2020): This popular AutoML open-source toolkit developed by AWS helps in getting a strong predictive performance \n",
    "# in various machine learning and deep learning models on text, image, and tabular data.\n",
    "!pip install autogluon\n",
    "\n",
    "!pip install --upgrade scikit-learn==1.0.0\n",
    "\n",
    "print('\\nREQUIRED PACKAGES INSTALLED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08154e30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For visualisation of plots\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3476927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For writing/saving structural alert images to excel file\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15274a43",
   "metadata": {},
   "source": [
    "# Automated machine learning model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Marcus Wei How Wang\n",
    "# 5 May 2022\n",
    "\n",
    "#======================================================================================#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from os.path import isfile\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "import pickle\n",
    "from random import randrange\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.core.metrics import make_scorer\n",
    "\n",
    "#======================================================================================#\n",
    "# This function gets the Morgan fingeprint given a SMILES dataframe and specified fingerprint parameters\n",
    "def get_Morgan_fingerprint(smiles,nBits,fingerprint_radius):\n",
    "    \n",
    "    '''smiles dataframe'''\n",
    "    error_idx_ls =[]\n",
    "    error_idx_ls.clear()\n",
    "    \n",
    "    rdkit_molecules=[Chem.MolFromSmiles(x) for x in smiles]\n",
    "    print(len(rdkit_molecules))\n",
    "    rdkit_fingerprint=[]\n",
    "    count = 0\n",
    "    fingerprint_length = int(nBits)\n",
    "    #print(rdkit_molecules[:1])\n",
    "    for mol in rdkit_molecules:\n",
    "        # if count % 1000 == 0:\n",
    "        #     print('Now fingerprinting {} of {}'.format(count,len(rdkit_molecules)))\n",
    "        bit_info={}\n",
    "        try:\n",
    "            fp=rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=fingerprint_radius, nBits=fingerprint_length,\n",
    "                                                          bitInfo=bit_info)\n",
    "        except:\n",
    "            # get indexes of errors with errors\n",
    "            error_idx_ls.append(rdkit_molecules.index(mol))\n",
    "\n",
    "        rdkit_fingerprint.append(fp)\n",
    "        count += 1\n",
    "        \n",
    "    fingerprint_df=pd.DataFrame([np.array(list(x)).astype(int) for x in rdkit_fingerprint])\n",
    "    #fingerprint_df = pd.DataFrame(rdkit_fingerprint,columns=['BV'])\n",
    "    \n",
    "    return fingerprint_df, error_idx_ls\n",
    "\n",
    "def get_MACCS_fingerprint(smiles):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fingerprint_df\n",
    "\n",
    "\n",
    "# This function is expecting a input csv with two columns 'SMILES' and 'Binary Activity'\n",
    "def split_train_test(csv,test_ratio,train_save,test_save,overwrite):\n",
    "    \n",
    "    # Read input and shuffle randomly\n",
    "    input_df = pd.read_csv(csv)\n",
    "    print(input_df)\n",
    "    input_df = input_df.sample(frac=1)\n",
    "    input_np = input_df.to_numpy()\n",
    "    \n",
    "    # split df randomly according to specified ratio\n",
    "    train_df, test_df = train_test_split(input_np, test_size=test_ratio)\n",
    "    \n",
    "    train_df = pd.DataFrame(train_df,columns=['SMILES','Binary Activity'])\n",
    "    test_df = pd.DataFrame(test_df,columns=['SMILES','Binary Activity'])\n",
    "    \n",
    "    # Save files\n",
    "    # Ovewrite existing file present in folder\n",
    "#     print(isfile(train_save))\n",
    "#     print(isfile(test_save))\n",
    "    if overwrite == False and isfile(train_save) == True:\n",
    "        train_save = train_save[:-4] + str(randrange(100)) + train_save[-4:]\n",
    "        train_df.to_csv(train_save)        \n",
    "    else:\n",
    "        train_df.to_csv(train_save)\n",
    "    \n",
    "    if overwrite == False and isfile(test_save) == True:\n",
    "        test_save = test_save[:-4] + str(randrange(100)) + test_save[-4:]\n",
    "        test_df.to_csv(test_save)        \n",
    "    else:\n",
    "        test_df.to_csv(test_save)\n",
    "    \n",
    "    \n",
    "    return train_save,test_save\n",
    "\n",
    "def most_probable_class(column_list):\n",
    "    col_val = set(column_list)\n",
    "    most_prob_class_count = 0\n",
    "    most_prob_class = 0\n",
    "    for ele in col_val:\n",
    "        class_count = column_list.count(ele)\n",
    "        if class_count > most_prob_class_count:\n",
    "            most_prob_class_count = class_count\n",
    "            most_prob_class = ele\n",
    "            \n",
    "    return most_prob_class\n",
    "\n",
    "\n",
    "def calc_baseline_acc(df_column_list):\n",
    "    \n",
    "    # Baseline accuracy is the accuracy when all the predicted classes are the most probable class\n",
    "    baseline_class = most_probable_class(df_column_list)\n",
    "    baseline_acc = df_column_list.count(baseline_class) / len(df_column_list) * 100\n",
    "    \n",
    "    print('Baseline accuracy:')\n",
    "    print(baseline_acc)\n",
    "    \n",
    "    return baseline_acc\n",
    "\n",
    "def acc(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "def sensitivity(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tp)/(tp+fn)\n",
    "\n",
    "def specificity(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tn)/(fp+tn)\n",
    "\n",
    "def tp_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return tp\n",
    "\n",
    "def fn_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # Needs the - sign since predictor.leaderboard flips the sign\n",
    "    return -fn  \n",
    "\n",
    "def fp_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # Needs the - sign since predictor.leaderboard flips the sign\n",
    "    return -fp  \n",
    "\n",
    "def tn_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return tn  \n",
    "\n",
    "\n",
    "def create_AutoGluon_extra_metrics(y_test,y_pred):\n",
    "\n",
    "    # Score functions need to have the definition:\n",
    "    # score_func(y, y_pred, **kwargs)\n",
    "    # Otherwise the calculations of the metrics will fail\n",
    "    \n",
    "    metrics_ls = []\n",
    "    metrics_ls.clear()\n",
    "    \n",
    "    # Calculate confusion matrix for custom metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    MCC = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "      \n",
    "    # Define custom scoring functions to pass to predictor.leaderboard()\n",
    "    ag_accuracy_scorer = make_scorer(name='Acc',\n",
    "                                 score_func=acc,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    ag_mcc_scorer = make_scorer(name='MCC',\n",
    "                                 score_func=matthews_corrcoef,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    ag_sensitivity_scorer = make_scorer(name='SE',\n",
    "                                 score_func=sensitivity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "\n",
    "    ag_specificity_scorer = make_scorer(name='SP',\n",
    "                                 score_func=specificity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "  \n",
    "    tn_scorer = make_scorer(name='TN',score_func=tn_func,greater_is_better=True)\n",
    "\n",
    "    \n",
    "      \n",
    "    fp_scorer = make_scorer(name='FP',score_func=fp_func,greater_is_better=False)\n",
    "\n",
    "    \n",
    "      \n",
    "    fn_scorer = make_scorer(name='FN',score_func=fn_func,greater_is_better=False)\n",
    "\n",
    "    \n",
    "\n",
    "    tp_scorer = make_scorer(name='TP',score_func=tp_func,greater_is_better=True)\n",
    "\n",
    "    \n",
    "    # Append all metrics to list\n",
    "    metrics_ls.append(tp_scorer)\n",
    "    metrics_ls.extend((fp_scorer, fn_scorer, tn_scorer, ag_sensitivity_scorer,\n",
    "                      ag_specificity_scorer, ag_accuracy_scorer, ag_mcc_scorer))\n",
    "#     print(metrics_ls)\n",
    "    return metrics_ls\n",
    "#======================================================================================#\n",
    "# The function is expecting a training and test set with SMILES and Binary Activity (2 columns in total)\n",
    "def AutoGluon(training_set,test_set,save_path,model_results,model_name):\n",
    "    print('\\nSETTING UP DATA FOR MODEL...')\n",
    "    dat_train = pd.read_csv(training_set, sep=',')\n",
    "    dat_train_smi = dat_train['SMILES'].tolist()\n",
    "    print('\\ndat_train no. of SMILES:')\n",
    "    print(len(dat_train_smi))\n",
    "\n",
    "    y_train = dat_train[['Binary Activity']]\n",
    "    X_train,error_idx_ls = get_Morgan_fingerprint(dat_train_smi,2048,2)\n",
    "\n",
    "    y_train = y_train.drop(error_idx_ls)\n",
    "    X_train = X_train.drop(error_idx_ls)\n",
    "\n",
    "    dat_test = pd.read_csv(test_set, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    y_test = dat_test[['Binary Activity']]\n",
    "    X_test,error_idx_ls = get_Morgan_fingerprint(dat_test_smi,2048,2)\n",
    "\n",
    "    # Drop rows with errors\n",
    "    y_test = y_test.drop(error_idx_ls)\n",
    "    X_test = X_test.drop(error_idx_ls)\n",
    "\n",
    "    print(X_train)\n",
    "    print(y_train)\n",
    "\n",
    "    print('\\nDATA SET UP FOR MODEL')\n",
    "    \n",
    "    print('\\nPREPARING AND TRAINING MODELS...')\n",
    "    # The dataframes need to be converted to the object used byu the AutoGluon package\n",
    "    label = 'Binary Activity'\n",
    "    train_data = TabularDataset(pd.concat([X_train,y_train],axis=1))\n",
    "    \n",
    "    # This the maximum time limit in seconds for each set of models\n",
    "    # Essentially, this means the models will take an estimated (13 * time_limit * (num_stack_levels +1)) \n",
    "    # amount of seconds to train. Note training time is also affected by the preset quality\n",
    "    time_limit = 60 * 60\n",
    "    \n",
    "    # Define metrics for validation here\n",
    "    # If using a different metric other than accuracy, note that the preset below needs to be changed as well\n",
    "    # Otherwise, the model will focus on acc\n",
    "    metric = 'accuracy'\n",
    "    ag_sensitivity_scorer = make_scorer(name='SE',\n",
    "                             score_func=sensitivity,\n",
    "                             optimum=1,\n",
    "                             greater_is_better=True)\n",
    "\n",
    "    ag_specificity_scorer = make_scorer(name='SP',\n",
    "                                 score_func=specificity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    # Best quality improves performance but takes longer to run. Medium_quality is the default setting.\n",
    "    # For more details see the AutoGluon package documentation\n",
    "#     preset = 'best_quality'\n",
    "    preset = 'medium_quality'\n",
    "    \n",
    "    # add hyperparameter_tune_kwargs if necessary\n",
    "#     num_trials = 25  # try at most n different hyperparameter configurations for each type of model\n",
    "#     search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "#     hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#         'num_trials': num_trials,\n",
    "#         'scheduler' : 'local',\n",
    "#         'searcher': search_strategy,\n",
    "#     }\n",
    "    \n",
    "    \n",
    "    # Model ensembling with stacking/bagging\n",
    "    # According to the documentation, \"beyond hyperparameter-tuning with a correctly-specified evaluation metric,\n",
    "    # two other methods to boost predictive performance are bagging and stack-ensembling. \n",
    "    # You’ll often see performance improve if you specify num_bag_folds = 5-10, \n",
    "    # num_stack_levels = 1-3 in the call to fit(), but this will increase training times and memory/disk usage.\"\n",
    "    # By default no hyperparameter optimisation is done ie. when hyperparameter_tune_kwargs is not specified\n",
    "    predictor = TabularPredictor(label, eval_metric=ag_sensitivity_scorer,path=model_name).fit(train_data,num_bag_folds=5, \n",
    "                                                                num_bag_sets=1, num_stack_levels=1, \n",
    "                                                                time_limit=time_limit,\n",
    "                                                                presets=preset\n",
    "#                                                                ,hyperparameter_tune_kwargs=hyperparameter_tune_kwargs\n",
    "                                                               )\n",
    "                                                               \n",
    "    print('\\nMODELS TRAINED')\n",
    "    \n",
    "    print('\\nEVALUATING MODELS...')\n",
    "    test_data = TabularDataset(pd.concat([X_test,y_test],axis=1))\n",
    "    y_test = test_data[label]  # values to predict\n",
    "    X_test = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "    X_test.head()\n",
    "    \n",
    "    y_pred = predictor.predict(X_test)\n",
    "    #print(\"Predictions:  \\n\", y_pred)\n",
    "    #perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n",
    "    \n",
    "    #print(\"TRUE VALUES:  \\n\", y_test)\n",
    "    y_test = y_test.tolist()\n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    add_metrics = create_AutoGluon_extra_metrics(y_test,y_pred)\n",
    "\n",
    "    results_df = predictor.leaderboard(test_data, silent=True,\n",
    "                                       extra_metrics=add_metrics\n",
    "                                      )\n",
    "    results_df.to_csv(model_results)\n",
    "    print(results_df)\n",
    "    print('\\nMODELS EVALUATED')   \n",
    "    \n",
    "    return\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "# Set filepaths for functions\n",
    "\n",
    "# Filepath of csv containing two columsn 'SMILES' and 'Binary Activity'\n",
    "root_desc = 'V2.0.1 Unified data max SP medium'\n",
    "root = 'C:/Users/mwhw3/Desktop/DART project/'\n",
    "input_path = root + root_desc + '.csv'\n",
    "\n",
    "total_runs = 5\n",
    "\n",
    "overall_save = root + 'AutoML models combined results/' + root_desc + ' ' + str(total_runs) +' runs.csv'\n",
    "#overall_save = root + 'AutoML models combined results/' + root_desc + ' all Unified data external prediction' + \\\n",
    "str(total_runs) +' runs.csv'\n",
    "\n",
    "for run in range(1,total_runs+1):\n",
    "    \n",
    "    print('\\n#=========================================================================================#')\n",
    "    print('#=========================================================================================#')\n",
    "    print('\\n                               NOW PERFORMING RUN {}\\n'.format(run))\n",
    "    print('#=========================================================================================#')\n",
    "    print('#=========================================================================================#')\n",
    "    \n",
    "    desc = root_desc + ' ' + str(run)\n",
    "    check_path = root + 'AutoML models/' + desc + '/' + 'Data/'\n",
    "    if os.path.exists(check_path)== False:\n",
    "        os.makedirs(check_path)\n",
    "        \n",
    "    # Save locations for training and test sets                              \n",
    "    train_save = root + 'AutoML models/' + desc + '/' + 'Data/' + desc + ' CSV train.csv'\n",
    "    test_save = root + 'AutoML models/' + desc + '/' + 'Data/' + desc + ' CSV test.csv'\n",
    "\n",
    "    # Save location for model results\n",
    "    model_name = root + 'AutoML models/' + desc + '/' + 'Models/'\n",
    "    if os.path.exists(model_name)== False:\n",
    "        os.makedirs(model_name)\n",
    "    check_path = root + 'AutoML models/' + desc + '/' + 'Results/'\n",
    "    if os.path.exists(check_path)== False:\n",
    "        os.makedirs(check_path)\n",
    "    model_results = root + 'AutoML models/' + desc + '/' + 'Results/' + desc + ' model results.csv'\n",
    "\n",
    "    # The AutoGluon package creates a folder if one is not present\n",
    "    # Otherwise it will save in the specified filepath\n",
    "    save_path = root + 'AutoML models/' + desc + '/'                            \n",
    "    #==============================================================================================#                             \n",
    "    # Main code\n",
    "    #input_csv = pd.read_csv(input_path)\n",
    "    training_set,test_set = split_train_test(input_path,0.2,train_save,test_save,True)                              \n",
    "\n",
    "    # If running AutoGluon model code                         \n",
    "    AutoGluon(training_set,test_set,save_path,model_results,model_name)\n",
    "    \n",
    "print('\\n#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('\\n                             ALL MODELS TRAINED AND EVALUATED\\n'                          )\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#    \n",
    "# Combine results for models across all runs    \n",
    "\n",
    "# Filepath of csv containing two columsn 'SMILES' and 'Binary Activity'\n",
    "#col_ls = ['TP','FP','FN','TN','SE','SP','Acc','MCC']\n",
    "col_ls = ['model','SE','SP','Acc','MCC']\n",
    "\n",
    "result_dict = {}\n",
    "for run in range(1,total_runs+1):\n",
    "    desc = root_desc + ' ' + str(run)\n",
    "    model_results = root + 'AutoML models/' + desc + '/' + 'Results/' + desc + ' model results.csv'\n",
    "    results_df = pd.read_csv(model_results)\n",
    "    results_df = results_df[col_ls]\n",
    "    results_name = str(results_df) + str(run)\n",
    "    result_dict[results_name] = results_df\n",
    "    \n",
    "combined_df = pd.concat(result_dict.values())\n",
    "#print(combined_df)\n",
    "mean_df = combined_df.groupby(by=['model']).mean()\n",
    "\n",
    "print('\\n#=========================================================================================#')\n",
    "print('\\n                                 DATAFRAME OF MEANS\\n'                                      )\n",
    "print('#=========================================================================================#\\n')\n",
    "\n",
    "mean_df['SE'] = 100 * mean_df['SE']\n",
    "mean_df['SP'] = 100 * mean_df['SP']\n",
    "mean_df['Acc'] = 100 * mean_df['Acc']\n",
    "\n",
    "mean_df = mean_df.round({'SE': 1,'SP': 1,'Acc': 1,'MCC': 3}).astype(str)\n",
    "print(mean_df)\n",
    "\n",
    "std_df = combined_df.groupby(by=['model']).agg(np.std)\n",
    "print('\\n#=========================================================================================#')\n",
    "print('\\n                                 DATAFRAME OF STD\\n'                                        )\n",
    "print('#=========================================================================================#\\n')\n",
    "\n",
    "std_df['SE'] = 100 * std_df['SE']\n",
    "std_df['SP'] = 100 * std_df['SP']\n",
    "std_df['Acc'] = 100 * std_df['Acc']\n",
    "\n",
    "std_df = std_df.round({'SE': 1,'SP': 1,'Acc': 1,'MCC': 3}).astype(str)\n",
    "print(std_df)\n",
    "\n",
    "overall_df = mean_df\n",
    "\n",
    "overall_df['SE'] = mean_df['SE'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['SE']\n",
    "overall_df['SP'] = mean_df['SP'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['SP']\n",
    "overall_df['Acc'] = mean_df['Acc'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['Acc']\n",
    "overall_df['MCC'] = mean_df['MCC'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['MCC']\n",
    "\n",
    "print('\\n#=========================================================================================#')\n",
    "print('\\n                                 OVERALL DATAFRAME\\n'                                        )\n",
    "print('#=========================================================================================#\\n')\n",
    "\n",
    "overall_df.to_csv(overall_save)\n",
    "print(overall_df)\n",
    "\n",
    "\n",
    "print('\\nFINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153279a",
   "metadata": {},
   "source": [
    "# For visualising feature space with PCA or t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca267cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for visualsiing feature space\n",
    "# t-SNE is used as it known to offer a better visual representation in the 2D plot as compared to PCA\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "\n",
    "\n",
    "# This function gets the Morgan fingeprint given a SMILES dataframe and specified fingerprint parameters\n",
    "def get_Morgan_fingerprint(smiles,nBits,fingerprint_radius):\n",
    "    \n",
    "    '''smiles dataframe'''\n",
    "    error_idx_ls =[]\n",
    "    error_idx_ls.clear()\n",
    "    \n",
    "    rdkit_molecules=[Chem.MolFromSmiles(x) for x in smiles]\n",
    "    print(len(rdkit_molecules))\n",
    "    rdkit_fingerprint=[]\n",
    "    count = 0\n",
    "    fingerprint_length = int(nBits)\n",
    "    #print(rdkit_molecules[:1])\n",
    "    for mol in rdkit_molecules:\n",
    "        # if count % 1000 == 0:\n",
    "        #     print('Now fingerprinting {} of {}'.format(count,len(rdkit_molecules)))\n",
    "        bit_info={}\n",
    "        try:\n",
    "            fp=rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=fingerprint_radius, nBits=fingerprint_length,\n",
    "                                                          bitInfo=bit_info)\n",
    "        except:\n",
    "            # get indexes of errors with errors\n",
    "            error_idx_ls.append(rdkit_molecules.index(mol))\n",
    "\n",
    "        rdkit_fingerprint.append(fp)\n",
    "        count += 1\n",
    "        \n",
    "    fingerprint_df=pd.DataFrame([np.array(list(x)).astype(int) for x in rdkit_fingerprint])\n",
    "    #fingerprint_df = pd.DataFrame(rdkit_fingerprint,columns=['BV'])\n",
    "    \n",
    "    return fingerprint_df, error_idx_ls\n",
    "\n",
    "\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "# Functions\n",
    "def input_to_tsne_plot(input_df,filename,perplex,iterations):\n",
    "    # Data should only contain the feature columns ie. no label column\n",
    "    print('\\n#=========================================================================================#')\n",
    "    print('\\n                                      RUNNING t-SNE for                                       \\n')\n",
    "    print('                             ' + str(filename) + '                             ')\n",
    "    print('\\n')\n",
    "    print('#=========================================================================================#\\n')\n",
    "    input_df['SMILES'].replace('', np.nan, inplace=True)\n",
    "    input_df.dropna(subset=['SMILES'], inplace=True)\n",
    "    input_df = input_df.drop_duplicates(subset=['SMILES'], keep='first', inplace=False)\n",
    "\n",
    "    to_concat = input_df\n",
    "    print(to_concat)\n",
    "    \n",
    "    input_df_smi = input_df['SMILES'].tolist()\n",
    "    print('\\ninput_df no. of SMILES:')\n",
    "    print(len(input_df_smi))\n",
    "\n",
    "    plot_data,error_idx_ls = get_Morgan_fingerprint(input_df_smi,2048,2)\n",
    "    plot_data = plot_data.drop(error_idx_ls)\n",
    "    to_concat = to_concat.drop(error_idx_ls)\n",
    "    to_concat = to_concat.reset_index(drop=True)\n",
    "    print(plot_data.head())\n",
    "\n",
    "    # t-SNE\n",
    "    time_start = time.time()\n",
    "    # This gives an ndarray of n samples and 2 columns\n",
    "    tsne = TSNE(n_components=2, perplexity=perplex,n_iter=iterations,verbose=1)\n",
    "    tsne_results = tsne.fit_transform(plot_data)\n",
    "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    \n",
    "    return tsne_results,to_concat\n",
    "\n",
    "# # PLotting the t-SNE results\n",
    "# # This gives the x-axis\n",
    "# plot_data['tsne-2d-one'] = tsne_results[:,0]\n",
    "# # This gives the y-axis\n",
    "# plot_data['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "def input_to_pca_plot(input_df,filename):\n",
    "    # Data should only contain the feature columns ie. no label column\n",
    "    print('\\n#=========================================================================================#')\n",
    "    print('\\n                                      RUNNING PCA for                                       \\n')\n",
    "    print('                             ' + str(filename) + '                             ')\n",
    "    print('\\n')\n",
    "    print('#=========================================================================================#\\n')\n",
    "    input_df['SMILES'].replace('', np.nan, inplace=True)\n",
    "    input_df.dropna(subset=['SMILES'], inplace=True)\n",
    "    input_df = input_df.drop_duplicates(subset=['SMILES'], keep='first', inplace=False)\n",
    "    to_concat = input_df\n",
    "    input_df_smi = input_df['SMILES'].tolist()\n",
    "    print('\\ninput_df no. of SMILES:')\n",
    "    print(len(input_df_smi))\n",
    "\n",
    "    plot_data,error_idx_ls = get_Morgan_fingerprint(input_df_smi,2048,2)\n",
    "    plot_data = plot_data.drop(error_idx_ls)\n",
    "    to_concat = to_concat.drop(error_idx_ls)\n",
    "    to_concat = to_concat.reset_index(drop=True)\n",
    "    print(plot_data.head())\n",
    "\n",
    "    # t-SNE\n",
    "    time_start = time.time()\n",
    "    # This gives an ndarray of n samples and 2 columns\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca_results = pca.fit_transform(plot_data)\n",
    "    print('\\nPercentage variance explained: {}'.format(pca.explained_variance_))\n",
    "    print('PCA done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    \n",
    "    return pca_results,to_concat\n",
    "\n",
    "def tsne_main(root_desc,perplex,iterations):\n",
    "    tsne_dict={}\n",
    "    for filename in root_desc:\n",
    "        index = root_desc.index(filename)\n",
    "\n",
    "        if filename == 'external test set 1 no outliers':\n",
    "            input_path = root + 'Outliers/' + filename + '.csv'\n",
    "\n",
    "        else:\n",
    "            input_path = root + filename + '.csv'\n",
    "\n",
    "        input_df = pd.read_csv(input_path, sep=',')\n",
    "\n",
    "        tsne_results,to_concat = input_to_tsne_plot(input_df,filename,perplex,iterations)\n",
    "\n",
    "        tsne_df = pd.DataFrame(tsne_results, columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "        print(tsne_df.head())\n",
    "\n",
    "        # Assign label by testing type for plotting later\n",
    "        if filename == 'V2.0.1 in vivo data':\n",
    "            new_col = 'in vivo'\n",
    "        if filename == 'V2.0.1 in vitro data':\n",
    "            new_col = 'in vitro'              \n",
    "        \n",
    "        # Assign label by toxicity endpoint for plotting later\n",
    "        if filename == 'V2.0.1 Developmental non-toxicants':\n",
    "            new_col = 'Developmental non-toxicants'\n",
    "        if filename == 'V2.0.1 Developmental toxicants':\n",
    "            new_col = 'Developmental toxicants'\n",
    "        if filename == 'V2.0.1 Reproductive non-toxicants':\n",
    "            new_col = 'Reproductive non-toxicants'\n",
    "        if filename == 'V2.0.1 Reproductive toxicants':\n",
    "            new_col = 'Reproductive toxicants'\n",
    "              \n",
    "        \n",
    "        # Assign label by source for plotting later\n",
    "        if filename == 'V2.0.1 Stemina data':\n",
    "            new_col = 'Stemina'\n",
    "\n",
    "        if filename == 'V2.0.1 Unified data no Stemina data':\n",
    "            new_col = 'Unified data no Stemina' \n",
    "\n",
    "        if filename == 'V2.0.1 VEGA data':\n",
    "            new_col = 'VEGA'\n",
    "\n",
    "        if filename == 'V2.0.1 DEREK data':\n",
    "            new_col = 'DEREK'\n",
    "            \n",
    "        if filename == 'V2.0.1 All other data':\n",
    "            new_col = 'All other data'\n",
    "            \n",
    "        if filename == 'V2.0.1 Challa data':\n",
    "            new_col = 'Challa et al.'\n",
    "\n",
    "        if filename == 'V2.0.1 Prenatal dev tox':\n",
    "            new_col = 'Prenatal dev tox'\n",
    "\n",
    "        if filename == 'V2.0.1 ML data':\n",
    "            new_col = 'Reproductive tox Feng et al.'\n",
    "\n",
    "        if filename == 'V2.0.1 external test set':\n",
    "            new_col = 'External test set'\n",
    "\n",
    "        if filename == 'external test set no outliers':\n",
    "            new_col = 'External test set (no outliers)'\n",
    "\n",
    "\n",
    "\n",
    "        tsne_df = tsne_df.assign(dataset = new_col)    \n",
    "\n",
    "        tsne_dict[new_col] = tsne_df\n",
    "    \n",
    "    return tsne_dict,to_concat\n",
    "\n",
    "def pca_main(root_desc):\n",
    "    pca_dict={}\n",
    "    for filename in root_desc:\n",
    "        index = root_desc.index(filename)\n",
    "\n",
    "        if filename == 'external test set no outliers':\n",
    "            input_path = root + 'Outliers/' + filename + '.csv'\n",
    "\n",
    "        else:\n",
    "            input_path = root + filename + '.csv'\n",
    "\n",
    "        input_df = pd.read_csv(input_path, sep=',')\n",
    "\n",
    "        pca_results,to_concat = input_to_pca_plot(input_df,filename)\n",
    "\n",
    "        pca_df = pd.DataFrame(pca_results, columns = ['pca-one','pca-two'])\n",
    "        print(pca_df.head())\n",
    "\n",
    "        \n",
    "        # Assign label by testing type for plotting later\n",
    "        if filename == 'V2.0.1 in vivo data':\n",
    "            new_col = 'in vivo'\n",
    "        if filename == 'V2.0.1 in vitro data':\n",
    "            new_col = 'in vitro'       \n",
    "        \n",
    "        # Assign label by toxicity endpoint for plotting later\n",
    "        if filename == 'V2.0.1 Developmental non-toxicants':\n",
    "            new_col = 'Developmental non-toxicants'\n",
    "        if filename == 'V2.0.1 Developmental toxicants':\n",
    "            new_col = 'Developmental toxicants'\n",
    "        if filename == 'V2.0.1 Reproductive non-toxicants':\n",
    "            new_col = 'Reproductive non-toxicants'\n",
    "        if filename == 'V2.0.1 Reproductive toxicants':\n",
    "            new_col = 'Reproductive toxicants'\n",
    "              \n",
    "        \n",
    "        # Assign label by source for plotting later\n",
    "        if filename == 'V2.0.1 Stemina data':\n",
    "            new_col = 'Stemina'\n",
    "\n",
    "        if filename == 'V2.0.1 Unified data no Stemina data':\n",
    "            new_col = 'Unified data no Stemina' \n",
    "\n",
    "        if filename == 'V2.0.1 VEGA data':\n",
    "            new_col = 'VEGA'\n",
    "\n",
    "        if filename == 'V2.0.1 DEREK data':\n",
    "            new_col = 'DEREK'\n",
    "            \n",
    "        if filename == 'V2.0.1 All other data':\n",
    "            new_col = 'All other data'\n",
    "            \n",
    "        if filename == 'V2.0.1 Challa data':\n",
    "            new_col = 'Challa et al.'\n",
    "\n",
    "        if filename == 'V2.0.1 Prenatal dev tox':\n",
    "            new_col = 'Prenatal dev tox'\n",
    "\n",
    "        if filename == 'V2.0.1 ML data':\n",
    "            new_col = 'Reproductive tox Feng et al.'\n",
    "\n",
    "        if filename == 'V2.0.1 external test set':\n",
    "            new_col = 'External test set'\n",
    "\n",
    "        if filename == 'external test set no outliers':\n",
    "            new_col = 'External test set (no outliers)'\n",
    "\n",
    "\n",
    "\n",
    "        pca_df = pca_df.assign(dataset = new_col)    \n",
    "\n",
    "        pca_dict[new_col] = pca_df\n",
    "    \n",
    "    return pca_dict,to_concat\n",
    "\n",
    "\n",
    "# Input test_points as a dataframe with ['tsne-2d-one'] and ['tsne-2d-two'] as columns\n",
    "def outlier_detection(query_point,test_points,threshold,points_in_circle):\n",
    "    \n",
    "    # Test if there are a certain number of test points within the circle of radius = threshold\n",
    "    # for a given query point\n",
    "    # Each point will have a x-value and a y-value   \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for n in range(0,len(test_points)):\n",
    "        \n",
    "        x = test_points.iloc[n]['tsne-2d-one']\n",
    "        y = test_points.iloc[n]['tsne-2d-two']\n",
    "        \n",
    "        x_center = query_point['tsne-2d-one']\n",
    "        y_center = query_point['tsne-2d-two']\n",
    "        \n",
    "        check = ((x - x_center)**2) + ((y - y_center)**2)\n",
    "        \n",
    "        if check <= (threshold**2):\n",
    "            count = count + 1\n",
    "    \n",
    "    # function will return true if there are <= the specified no. of points in circle within the radius/threshold\n",
    "    if count <= points_in_circle:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def calc_tsne_outliers(value):\n",
    "    print('CALCULATING OUTLIERS...')\n",
    "    query_df = tsne_dict['External test set 1']\n",
    "    test_df = tsne_dict['Unified data no Stemina']\n",
    "\n",
    "    outlier_ls = []\n",
    "    outlier_ls.clear()\n",
    "\n",
    "    # The threshold specified is the radius\n",
    "    # TYhe values should be a reasonable distance on the t-SNE plot\n",
    "    threshold = 25\n",
    "    points_in_circle = 1\n",
    "\n",
    "    for query in range(0,len(query_df)):\n",
    "\n",
    "        if query % 10 == 0:\n",
    "            print('\\nNOW FINDING OUTLIERS FOR INDEX {}'.format(query))\n",
    "\n",
    "        query_point = query_df.iloc[query] \n",
    "\n",
    "        if outlier_detection(query_point,test_df,threshold,points_in_circle) == True:\n",
    "            outlier_ls.append(query)\n",
    "\n",
    "\n",
    "    # Get outliers in external test set as df for easy access if necessary\n",
    "    index = root_desc.index(filename)\n",
    "    input_path = root + root_desc[1] + '.csv'\n",
    "    input_df = pd.read_csv(input_path, sep=',')\n",
    "\n",
    "    outlier_df = input_df.iloc[outlier_ls]\n",
    "    print('\\n')\n",
    "    print('{} OUTLIERS WERE FOUND ON THIS RUN'.format(outlier_df))\n",
    "\n",
    "    print('\\n')\n",
    "    print(outlier_df.head())\n",
    "    \n",
    "    outlier_df.to_csv(outlier_save)\n",
    "\n",
    "    # save external test set without outliers\n",
    "    ext_no_outlier_df = input_df.drop(outlier_ls)\n",
    "    print(ext_no_outlier_df)\n",
    "    ext_no_outlier_df.to_csv(ext_no_outlier)        \n",
    "    \n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "# Main code\n",
    "# Filepaths of csv containing two columsn 'SMILES' and 'Binary Activity' to be input in\n",
    "# root_desc as a list. This is for plotting t-SNE results of different datasets on the same plot\n",
    "\n",
    "root = 'C:/Users/mwhw3/Desktop/DART project/'\n",
    "\n",
    "# root_desc = ['V2.0.1 Stemina data']\n",
    "# save_desc = 'Stemina data'\n",
    "\n",
    "# root_desc = ['V2.0.1 Stemina data','V2.0.1 VEGA data','V2.0.1 DEREK data','V2.0.1 Challa data',\n",
    "#              'V2.0.1 Prenatal dev tox', 'V2.0.1 ML data','V2.0.1 All other data']\n",
    "# save_desc = 'Data by source'\n",
    "\n",
    "# root_desc = ['V2.0.1 Developmental non-toxicants','V2.0.1 Developmental toxicants',\n",
    "#               'V2.0.1 Reproductive non-toxicants','V2.0.1 Reproductive toxicants']\n",
    "# save_desc = 'Data by toxicity endpoint'\n",
    "\n",
    "root_desc = ['V2.0.1 in vivo data','V2.0.1 in vitro data']\n",
    "save_desc = 'Data by testing type'\n",
    "\n",
    "\n",
    "# Save location for resulting sns plot\n",
    "plot_save_tsne = root + 'Feature plots/'+ save_desc + '_tsne.tiff'\n",
    "plot_save_pca = root + 'Feature plots/'+ save_desc + '_pca.tiff'\n",
    "plot_save_pca_facet = root + 'Feature plots/'+ save_desc + '_pca_facet.tiff'\n",
    "#plot_save = root + 'SNS plots/'+ 'Compare Unified data with Stemina' + '.tiff'\n",
    "#plot_save = root + 'SNS plots/'+ 'Stemina data only' + '.tiff'\n",
    "#plot_save = root + 'SNS plots/'+ 'Predicting on external test set 1' + '.tiff'\n",
    "\n",
    "# Change tsne parameters\n",
    "# Note perplexity is the guess of the number of nearest neighbours per data point\n",
    "\n",
    "# perplex_ls = [10]\n",
    "perplex_ls = [10,20,40,60,80]\n",
    "# iterations = 5000\n",
    "iterations = 1000\n",
    "#==================================================================================#  \n",
    "# # Plot data from specified feature visualisation method on the same axis\n",
    "\n",
    "# For plotting tsne\n",
    "# for perplex in perplex_ls:\n",
    "#     print('\\nRUNNING tsne with perplexity:',perplex)\n",
    "#     tsne_dict,to_concat = tsne_main(root_desc,perplex,iterations)\n",
    "#     tsne_concatenated = pd.concat(tsne_dict.values(), sort=False, ignore_index=False)\n",
    "#     tsne_concatenated.columns= ['tsne-2d-one','tsne-2d-two','dataset']\n",
    "#     plt.figure(figsize=(16,10))\n",
    "#     sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", data=tsne_concatenated,\n",
    "#                     hue='dataset', palette=\"colorblind\", legend=\"full\", style='dataset')\n",
    "\n",
    "#     plot_save_tsne = root + 'Feature plots/'+ save_desc + '_tsne_perplex' + str(perplex) + '.tiff'\n",
    "#     plt.savefig(plot_save_tsne)\n",
    "#     plt.show()\n",
    "\n",
    "# For plotting PCA\n",
    "pca_dict,to_concat = pca_main(root_desc)\n",
    "pca_concatenated = pd.concat(pca_dict.values(), sort=False, ignore_index=False)  \n",
    "pca_concatenated.columns= ['pca-one','pca-two','dataset']\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(x=\"pca-one\", y=\"pca-two\", data=pca_concatenated,\n",
    "                hue='dataset', palette=\"colorblind\", legend=\"full\", style='dataset')\n",
    "\n",
    "# Get tick labels for facet plot\n",
    "# Remove first and last tick label which are the plot boundaries \n",
    "xticks = list(plt.xticks()[0])\n",
    "xticks = [int(x) for x in xticks]\n",
    "xticks = xticks[1:-1]\n",
    "\n",
    "yticks = list(plt.yticks()[0])\n",
    "yticks = [int(y) for y in yticks]\n",
    "yticks = yticks[1:-1]\n",
    "print(xticks)\n",
    "print(yticks)\n",
    "\n",
    "#plt.savefig(plot_save_pca)\n",
    "plt.show()\n",
    "\n",
    "# Plot Facet grid for PCA plot to better visualise the global structure of the feature space\n",
    "# This also enables the overlapping compounds to be visaulised better\n",
    "plots_per_row = 2             # This controls how many plots appear in the Facet Grid plot per row\n",
    "facet = sns.FacetGrid(pca_concatenated, col=\"dataset\", col_wrap=plots_per_row, palette=\"colorblind\", \n",
    "                      hue=\"dataset\", height = 5)\n",
    "facet = (facet.map(plt.scatter, \"pca-one\", \"pca-two\", s=10, edgecolor=\"w\"))\n",
    "\n",
    "facet.set(xticks=xticks, yticks=yticks)\n",
    "plt.savefig(plot_save_pca_facet)\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "print('\\nFINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f1ba2",
   "metadata": {},
   "source": [
    "# For loading all trained models and predicting on external test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0eed632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "                               NOW PERFORMING RUN 1\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Developmental toxicity 1/Models/\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Reproductive toxicity 1/Data/V2.0.1 Reproductive toxicity 1 CSV test.csv\n",
      "\n",
      "SETTING UP DATA FOR MODEL...\n",
      "\n",
      "dat_test no. of SMILES:\n",
      "322\n",
      "322\n",
      "\n",
      "DATA SET UP FOR MODEL\n",
      "                      model  score_test   TP  FP  FN   TN        SE        SP  \\\n",
      "0   RandomForestEntr_BAG_L2    0.782609  146  46  24  106  0.858824  0.697368   \n",
      "1           CatBoost_BAG_L2    0.782609  147  47  23  105  0.864706  0.690789   \n",
      "2   RandomForestGini_BAG_L2    0.773292  146  49  24  103  0.858824  0.677632   \n",
      "3       WeightedEnsemble_L3    0.773292  147  50  23  102  0.864706  0.671053   \n",
      "4     ExtraTreesGini_BAG_L2    0.770186  146  50  24  102  0.858824  0.671053   \n",
      "5            XGBoost_BAG_L2    0.770186  145  49  25  103  0.852941  0.677632   \n",
      "6     NeuralNetTorch_BAG_L2    0.770186  145  49  25  103  0.852941  0.677632   \n",
      "7     ExtraTreesEntr_BAG_L1    0.767081  149  54  21   98  0.876471  0.644737   \n",
      "8   RandomForestEntr_BAG_L1    0.763975  150  56  20   96  0.882353  0.631579   \n",
      "9       WeightedEnsemble_L2    0.763975  149  55  21   97  0.876471  0.638158   \n",
      "10    ExtraTreesEntr_BAG_L2    0.763975  146  52  24  100  0.858824  0.657895   \n",
      "11  RandomForestGini_BAG_L1    0.760870  150  57  20   95  0.882353  0.625000   \n",
      "12          LightGBM_BAG_L2    0.760870  146  53  24   99  0.858824  0.651316   \n",
      "13     LightGBMLarge_BAG_L1    0.757764  149  57  21   95  0.876471  0.625000   \n",
      "14     LightGBMLarge_BAG_L2    0.757764  148  56  22   96  0.870588  0.631579   \n",
      "15    ExtraTreesGini_BAG_L1    0.754658  151  60  19   92  0.888235  0.605263   \n",
      "16        LightGBMXT_BAG_L1    0.751553  139  49  31  103  0.817647  0.677632   \n",
      "17          LightGBM_BAG_L1    0.751553  139  49  31  103  0.817647  0.677632   \n",
      "18    NeuralNetTorch_BAG_L1    0.748447  147  58  23   94  0.864706  0.618421   \n",
      "19   NeuralNetFastAI_BAG_L1    0.748447  146  57  24   95  0.858824  0.625000   \n",
      "20        LightGBMXT_BAG_L2    0.748447  145  56  25   96  0.852941  0.631579   \n",
      "21           XGBoost_BAG_L1    0.732919  139  55  31   97  0.817647  0.638158   \n",
      "22   NeuralNetFastAI_BAG_L2    0.732919  144  60  26   92  0.847059  0.605263   \n",
      "23          CatBoost_BAG_L1    0.726708  146  64  24   88  0.858824  0.578947   \n",
      "\n",
      "         Acc       MCC  score_val  pred_time_test  pred_time_val   fit_time  \\\n",
      "0   0.782609  0.565912   0.684654        4.391332      11.578772  49.289300   \n",
      "1   0.782609  0.566658   0.704328        4.953881      11.063233  52.820926   \n",
      "2   0.773292  0.547975   0.680157        4.375706      11.578890  49.304986   \n",
      "3   0.773292  0.548817   0.711074        5.407028      15.270674  66.059597   \n",
      "4   0.770186  0.542010   0.685216        4.391331      11.578888  49.368411   \n",
      "5   0.770186  0.541234   0.706015        4.406957      10.313177  50.820784   \n",
      "6   0.770186  0.541234   0.697583        4.438210      10.344420  61.070333   \n",
      "7   0.767081  0.539058   0.681844        0.078121       1.453227   1.218721   \n",
      "8   0.763975  0.534428   0.680720        0.078131       1.359471   1.249996   \n",
      "9   0.763975  0.533192   0.698145        3.906932       9.891262  28.864722   \n",
      "10  0.763975  0.530099   0.685779        4.391324      11.583033  49.273800   \n",
      "11  0.760870  0.528594   0.672850        0.078129       1.359469   1.250022   \n",
      "12  0.760870  0.524150   0.688589        4.422584      10.328803  50.039477   \n",
      "13  0.757764  0.521470   0.680720        0.125008       0.125009   5.905820   \n",
      "14  0.757764  0.520282   0.686903        4.438211      10.328797  54.258531   \n",
      "15  0.754658  0.518357   0.680157        0.078131       1.390642   1.187580   \n",
      "16  0.751553  0.501608   0.668915        0.109383       0.093754   2.156405   \n",
      "17  0.751553  0.501608   0.668915        0.109383       0.109387   2.054861   \n",
      "18  0.748447  0.501462   0.672288        0.093748       0.078152   9.562547   \n",
      "19  0.748447  0.500394   0.659921        2.938123       3.422127  12.250870   \n",
      "20  0.748447  0.499422   0.677909        4.406958      10.328802  49.961347   \n",
      "21  0.732919  0.464964   0.668915        0.078131       0.062503   2.312665   \n",
      "22  0.732919  0.468638   0.672850        7.266537      13.516523  60.649053   \n",
      "23  0.726708  0.458854   0.670039        0.546914       0.781303   8.952353   \n",
      "\n",
      "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0                  0.078130                1.343726           1.187460   \n",
      "1                  0.640679                0.828188           4.719086   \n",
      "2                  0.062505                1.343845           1.203147   \n",
      "3                  0.000000                0.000000           0.737043   \n",
      "4                  0.078129                1.343843           1.266571   \n",
      "5                  0.093755                0.078132           2.718945   \n",
      "6                  0.125008                0.109375          12.968493   \n",
      "7                  0.078121                1.453227           1.218721   \n",
      "8                  0.078131                1.359471           1.249996   \n",
      "9                  0.000000                0.015635           0.700320   \n",
      "10                 0.078122                1.347988           1.171960   \n",
      "11                 0.078129                1.359469           1.250022   \n",
      "12                 0.109383                0.093757           1.937637   \n",
      "13                 0.125008                0.125009           5.905820   \n",
      "14                 0.125009                0.093752           6.156691   \n",
      "15                 0.078131                1.390642           1.187580   \n",
      "16                 0.109383                0.093754           2.156405   \n",
      "17                 0.109383                0.109387           2.054861   \n",
      "18                 0.093748                0.078152           9.562547   \n",
      "19                 2.938123                3.422127          12.250870   \n",
      "20                 0.093756                0.093757           1.859508   \n",
      "21                 0.078131                0.062503           2.312665   \n",
      "22                 2.953335                3.281478          12.547214   \n",
      "23                 0.546914                0.781303           8.952353   \n",
      "\n",
      "    stack_level  can_infer  fit_order  \n",
      "0             2       True         16  \n",
      "1             2       True         17  \n",
      "2             2       True         15  \n",
      "3             3       True         24  \n",
      "4             2       True         18  \n",
      "5             2       True         21  \n",
      "6             2       True         22  \n",
      "7             1       True          7  \n",
      "8             1       True          4  \n",
      "9             2       True         12  \n",
      "10            2       True         19  \n",
      "11            1       True          3  \n",
      "12            2       True         14  \n",
      "13            1       True         11  \n",
      "14            2       True         23  \n",
      "15            1       True          6  \n",
      "16            1       True          1  \n",
      "17            1       True          2  \n",
      "18            1       True         10  \n",
      "19            1       True          8  \n",
      "20            2       True         13  \n",
      "21            1       True          9  \n",
      "22            2       True         20  \n",
      "23            1       True          5  \n",
      "\n",
      "MODELS EVALUATED\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "                               NOW PERFORMING RUN 2\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Developmental toxicity 2/Models/\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Reproductive toxicity 2/Data/V2.0.1 Reproductive toxicity 2 CSV test.csv\n",
      "\n",
      "SETTING UP DATA FOR MODEL...\n",
      "\n",
      "dat_test no. of SMILES:\n",
      "322\n",
      "322\n",
      "\n",
      "DATA SET UP FOR MODEL\n",
      "                      model  score_test   TP  FP  FN   TN        SE        SP  \\\n",
      "0         LightGBMXT_BAG_L2    0.832298  141  36  18  127  0.886792  0.779141   \n",
      "1            XGBoost_BAG_L2    0.829193  139  35  20  128  0.874214  0.785276   \n",
      "2     NeuralNetTorch_BAG_L2    0.829193  137  33  22  130  0.861635  0.797546   \n",
      "3       WeightedEnsemble_L3    0.826087  136  33  23  130  0.855346  0.797546   \n",
      "4     ExtraTreesEntr_BAG_L2    0.822981  139  37  20  126  0.874214  0.773006   \n",
      "5   RandomForestGini_BAG_L2    0.822981  134  32  25  131  0.842767  0.803681   \n",
      "6   RandomForestEntr_BAG_L2    0.819876  138  37  21  126  0.867925  0.773006   \n",
      "7      LightGBMLarge_BAG_L2    0.819876  138  37  21  126  0.867925  0.773006   \n",
      "8           CatBoost_BAG_L2    0.819876  135  34  24  129  0.849057  0.791411   \n",
      "9     ExtraTreesGini_BAG_L2    0.816770  139  39  20  124  0.874214  0.760736   \n",
      "10   NeuralNetFastAI_BAG_L2    0.813665  139  40  20  123  0.874214  0.754601   \n",
      "11  RandomForestEntr_BAG_L1    0.807453  142  45  17  118  0.893082  0.723926   \n",
      "12    ExtraTreesEntr_BAG_L1    0.807453  141  44  18  119  0.886792  0.730061   \n",
      "13    ExtraTreesGini_BAG_L1    0.807453  141  44  18  119  0.886792  0.730061   \n",
      "14          LightGBM_BAG_L2    0.807453  136  39  23  124  0.855346  0.760736   \n",
      "15     LightGBMLarge_BAG_L1    0.804348  141  45  18  118  0.886792  0.723926   \n",
      "16  RandomForestGini_BAG_L1    0.801242  142  47  17  116  0.893082  0.711656   \n",
      "17      WeightedEnsemble_L2    0.801242  141  46  18  117  0.886792  0.717791   \n",
      "18          CatBoost_BAG_L1    0.791925  135  43  24  120  0.849057  0.736196   \n",
      "19   NeuralNetFastAI_BAG_L1    0.782609  137  48  22  115  0.861635  0.705521   \n",
      "20           XGBoost_BAG_L1    0.779503  133  45  26  118  0.836478  0.723926   \n",
      "21          LightGBM_BAG_L1    0.776398  133  46  26  117  0.836478  0.717791   \n",
      "22    NeuralNetTorch_BAG_L1    0.776398  138  51  21  112  0.867925  0.687117   \n",
      "23        LightGBMXT_BAG_L1    0.776398  133  46  26  117  0.836478  0.717791   \n",
      "\n",
      "         Acc       MCC  score_val  pred_time_test  pred_time_val   fit_time  \\\n",
      "0   0.832298  0.669195   0.694210        4.515935      10.257179  53.389760   \n",
      "1   0.829193  0.661599   0.688589        4.508816      10.225932  53.553427   \n",
      "2   0.829193  0.660163   0.698707        4.625318      10.241556  58.224844   \n",
      "3   0.826087  0.653649   0.708263        8.266202      19.897201  74.133165   \n",
      "4   0.822981  0.649997   0.694772        4.484675      11.507269  52.771872   \n",
      "5   0.822981  0.646710   0.690275        4.484682      11.491642  52.693918   \n",
      "6   0.819876  0.643318   0.686341        4.484683      11.647751  52.709578   \n",
      "7   0.819876  0.643318   0.677347        4.547185      10.241554  58.490452   \n",
      "8   0.819876  0.641210   0.698707        4.969101      11.022856  56.428636   \n",
      "9   0.816770  0.638470   0.691400        4.484683      11.491639  52.662666   \n",
      "10  0.813665  0.632733   0.669477        7.375513      13.475029  63.615918   \n",
      "11  0.807453  0.625166   0.685216        0.062505       1.374944   1.234415   \n",
      "12  0.807453  0.623776   0.682968        0.078121       1.350309   1.202996   \n",
      "13  0.807453  0.623776   0.683530        0.078131       1.343843   1.203135   \n",
      "14  0.807453  0.618377   0.686341        4.515935      10.241553  53.475298   \n",
      "15  0.804348  0.618170   0.679033        0.125008       0.093712   5.906560   \n",
      "16  0.801242  0.614049   0.693086        0.093757       1.390682   1.203126   \n",
      "17  0.801242  0.612578   0.695897        0.312514       5.459778   5.550496   \n",
      "18  0.791925  0.588498   0.678471        0.625044       0.765679   8.953774   \n",
      "19  0.782609  0.573521   0.666105        2.968961       3.469326  12.037109   \n",
      "20  0.779503  0.563511   0.674536        0.078129       0.046881   1.953264   \n",
      "21  0.776398  0.557723   0.681282        0.093757       0.093760   1.937638   \n",
      "22  0.776398  0.563587   0.676785        0.093757       0.109280  13.889876   \n",
      "23  0.776398  0.557723   0.681282        0.109383       0.109381   1.968889   \n",
      "\n",
      "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0                  0.109383                0.109382           1.898978   \n",
      "1                  0.102264                0.078135           2.062645   \n",
      "2                  0.218766                0.093759           6.734062   \n",
      "3                  0.015626                0.000000           0.704485   \n",
      "4                  0.078123                1.359472           1.281090   \n",
      "5                  0.078130                1.343845           1.203136   \n",
      "6                  0.078130                1.499954           1.218796   \n",
      "7                  0.140633                0.093757           6.999670   \n",
      "8                  0.562549                0.875059           4.937854   \n",
      "9                  0.078130                1.343842           1.171884   \n",
      "10                 2.968961                3.327232          12.125137   \n",
      "11                 0.062505                1.374944           1.234415   \n",
      "12                 0.078121                1.350309           1.202996   \n",
      "13                 0.078131                1.343843           1.203135   \n",
      "14                 0.109383                0.093756           1.984516   \n",
      "15                 0.125008                0.093712           5.906560   \n",
      "16                 0.093757                1.390682           1.203126   \n",
      "17                 0.000000                0.000000           0.706825   \n",
      "18                 0.625044                0.765679           8.953774   \n",
      "19                 2.968961                3.469326          12.037109   \n",
      "20                 0.078129                0.046881           1.953264   \n",
      "21                 0.093757                0.093760           1.937638   \n",
      "22                 0.093757                0.109280          13.889876   \n",
      "23                 0.109383                0.109381           1.968889   \n",
      "\n",
      "    stack_level  can_infer  fit_order  \n",
      "0             2       True         13  \n",
      "1             2       True         21  \n",
      "2             2       True         22  \n",
      "3             3       True         24  \n",
      "4             2       True         19  \n",
      "5             2       True         15  \n",
      "6             2       True         16  \n",
      "7             2       True         23  \n",
      "8             2       True         17  \n",
      "9             2       True         18  \n",
      "10            2       True         20  \n",
      "11            1       True          4  \n",
      "12            1       True          7  \n",
      "13            1       True          6  \n",
      "14            2       True         14  \n",
      "15            1       True         11  \n",
      "16            1       True          3  \n",
      "17            2       True         12  \n",
      "18            1       True          5  \n",
      "19            1       True          8  \n",
      "20            1       True          9  \n",
      "21            1       True          2  \n",
      "22            1       True         10  \n",
      "23            1       True          1  \n",
      "\n",
      "MODELS EVALUATED\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "                               NOW PERFORMING RUN 3\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Developmental toxicity 3/Models/\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Reproductive toxicity 3/Data/V2.0.1 Reproductive toxicity 3 CSV test.csv\n",
      "\n",
      "SETTING UP DATA FOR MODEL...\n",
      "\n",
      "dat_test no. of SMILES:\n",
      "322\n",
      "322\n",
      "\n",
      "DATA SET UP FOR MODEL\n",
      "                      model  score_test   TP  FP  FN   TN        SE        SP  \\\n",
      "0     ExtraTreesEntr_BAG_L1    0.819876  162  40  18  102  0.900000  0.718310   \n",
      "1   RandomForestGini_BAG_L1    0.819876  163  41  17  101  0.905556  0.711268   \n",
      "2     ExtraTreesGini_BAG_L1    0.816770  163  42  17  100  0.905556  0.704225   \n",
      "3   RandomForestEntr_BAG_L1    0.816770  161  40  19  102  0.894444  0.718310   \n",
      "4       WeightedEnsemble_L2    0.813665  162  42  18  100  0.900000  0.704225   \n",
      "5           CatBoost_BAG_L2    0.801242  150  34  30  108  0.833333  0.760563   \n",
      "6      LightGBMLarge_BAG_L1    0.798137  159  44  21   98  0.883333  0.690141   \n",
      "7     ExtraTreesEntr_BAG_L2    0.798137  152  37  28  105  0.844444  0.739437   \n",
      "8   RandomForestGini_BAG_L2    0.788820  151  39  29  103  0.838889  0.725352   \n",
      "9    NeuralNetFastAI_BAG_L1    0.785714  156  45  24   97  0.866667  0.683099   \n",
      "10  RandomForestEntr_BAG_L2    0.785714  150  39  30  103  0.833333  0.725352   \n",
      "11           XGBoost_BAG_L2    0.785714  150  39  30  103  0.833333  0.725352   \n",
      "12    ExtraTreesGini_BAG_L2    0.785714  152  41  28  101  0.844444  0.711268   \n",
      "13        LightGBMXT_BAG_L2    0.785714  154  43  26   99  0.855556  0.697183   \n",
      "14      WeightedEnsemble_L3    0.782609  148  38  32  104  0.822222  0.732394   \n",
      "15        LightGBMXT_BAG_L1    0.779503  153  44  27   98  0.850000  0.690141   \n",
      "16          LightGBM_BAG_L1    0.779503  153  44  27   98  0.850000  0.690141   \n",
      "17          LightGBM_BAG_L2    0.779503  148  39  32  103  0.822222  0.725352   \n",
      "18     LightGBMLarge_BAG_L2    0.773292  152  45  28   97  0.844444  0.683099   \n",
      "19    NeuralNetTorch_BAG_L1    0.767081  156  51  24   91  0.866667  0.640845   \n",
      "20    NeuralNetTorch_BAG_L2    0.767081  148  43  32   99  0.822222  0.697183   \n",
      "21          CatBoost_BAG_L1    0.763975  155  51  25   91  0.861111  0.640845   \n",
      "22   NeuralNetFastAI_BAG_L2    0.757764  152  50  28   92  0.844444  0.647887   \n",
      "23           XGBoost_BAG_L1    0.751553  152  52  28   90  0.844444  0.633803   \n",
      "\n",
      "         Acc       MCC  score_val  pred_time_test  pred_time_val   fit_time  \\\n",
      "0   0.819876  0.634922   0.671726        0.078122       1.343844   1.203208   \n",
      "1   0.819876  0.635602   0.670039        0.093756       1.390723   1.250063   \n",
      "2   0.816770  0.629484   0.676785        0.078130       1.343842   1.203079   \n",
      "3   0.816770  0.628168   0.666667        0.078131       1.343846   1.234332   \n",
      "4   0.813665  0.622620   0.694210        1.203208       5.187771  32.121597   \n",
      "5   0.801242  0.595858   0.689151        5.081054      11.000691  54.007837   \n",
      "6   0.798137  0.589892   0.678471        0.140635       0.109275   6.936582   \n",
      "7   0.798137  0.588773   0.675098        4.515424      11.500720  50.601215   \n",
      "8   0.788820  0.569615   0.688027        4.515432      11.485097  50.523148   \n",
      "9   0.785714  0.563595   0.668915        2.983465       3.515877  12.327976   \n",
      "10  0.785714  0.563367   0.684654        4.515433      11.500723  50.523084   \n",
      "11  0.785714  0.563367   0.696459        4.531059      10.219384  51.320143   \n",
      "12  0.785714  0.563063   0.684092        4.531059      11.516347  50.523125   \n",
      "13  0.785714  0.563135   0.693648        4.546685      10.297513  51.476408   \n",
      "14  0.782609  0.557503   0.708263        5.456079      13.829005  71.049113   \n",
      "15  0.779503  0.550300   0.672288        0.109382       0.109383   2.203284   \n",
      "16  0.779503  0.550300   0.672288        0.109995       0.109381   2.125153   \n",
      "17  0.779503  0.550980   0.690275        4.546685      10.250634  51.288891   \n",
      "18  0.773292  0.537465   0.674536        4.546684      10.281770  55.538376   \n",
      "19  0.767081  0.525887   0.668353        0.078129       0.093775   8.937219   \n",
      "20  0.767081  0.524970   0.694210        4.546684      10.297499  61.312281   \n",
      "21  0.763975  0.519139   0.676785        0.625053       0.781303   9.695826   \n",
      "22  0.757764  0.505559   0.670601        7.406265      13.703245  61.569994   \n",
      "23  0.751553  0.492807   0.665542        0.062504       0.031254   2.218907   \n",
      "\n",
      "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0                  0.078122                1.343844           1.203208   \n",
      "1                  0.093756                1.390723           1.250063   \n",
      "2                  0.078130                1.343842           1.203079   \n",
      "3                  0.078131                1.343846           1.234332   \n",
      "4                  0.000000                0.015626           0.692336   \n",
      "5                  0.643751                0.828188           4.672208   \n",
      "6                  0.140635                0.109275           6.936582   \n",
      "7                  0.078122                1.328217           1.265586   \n",
      "8                  0.078130                1.312594           1.187519   \n",
      "9                  2.983465                3.515877          12.327976   \n",
      "10                 0.078130                1.328219           1.187455   \n",
      "11                 0.093757                0.046880           1.984514   \n",
      "12                 0.093757                1.343844           1.187496   \n",
      "13                 0.109383                0.125010           2.140779   \n",
      "14                 0.000000                0.000000           0.705095   \n",
      "15                 0.109382                0.109383           2.203284   \n",
      "16                 0.109995                0.109381           2.125153   \n",
      "17                 0.109383                0.078130           1.953262   \n",
      "18                 0.109382                0.109267           6.202747   \n",
      "19                 0.078129                0.093775           8.937219   \n",
      "20                 0.109382                0.124995          11.976652   \n",
      "21                 0.625053                0.781303           9.695826   \n",
      "22                 2.968962                3.530742          12.234365   \n",
      "23                 0.062504                0.031254           2.218907   \n",
      "\n",
      "    stack_level  can_infer  fit_order  \n",
      "0             1       True          7  \n",
      "1             1       True          3  \n",
      "2             1       True          6  \n",
      "3             1       True          4  \n",
      "4             2       True         12  \n",
      "5             2       True         17  \n",
      "6             1       True         11  \n",
      "7             2       True         19  \n",
      "8             2       True         15  \n",
      "9             1       True          8  \n",
      "10            2       True         16  \n",
      "11            2       True         21  \n",
      "12            2       True         18  \n",
      "13            2       True         13  \n",
      "14            3       True         24  \n",
      "15            1       True          1  \n",
      "16            1       True          2  \n",
      "17            2       True         14  \n",
      "18            2       True         23  \n",
      "19            1       True         10  \n",
      "20            2       True         22  \n",
      "21            1       True          5  \n",
      "22            2       True         20  \n",
      "23            1       True          9  \n",
      "\n",
      "MODELS EVALUATED\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "                               NOW PERFORMING RUN 4\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Developmental toxicity 4/Models/\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Reproductive toxicity 4/Data/V2.0.1 Reproductive toxicity 4 CSV test.csv\n",
      "\n",
      "SETTING UP DATA FOR MODEL...\n",
      "\n",
      "dat_test no. of SMILES:\n",
      "322\n",
      "322\n",
      "\n",
      "DATA SET UP FOR MODEL\n",
      "                      model  score_test   TP  FP  FN   TN        SE        SP  \\\n",
      "0           CatBoost_BAG_L2    0.826087  140  33  23  126  0.858896  0.792453   \n",
      "1   RandomForestEntr_BAG_L2    0.819876  139  34  24  125  0.852761  0.786164   \n",
      "2      LightGBMLarge_BAG_L1    0.816770  145  41  18  118  0.889571  0.742138   \n",
      "3            XGBoost_BAG_L1    0.813665  140  37  23  122  0.858896  0.767296   \n",
      "4   RandomForestGini_BAG_L2    0.810559  135  33  28  126  0.828221  0.792453   \n",
      "5         LightGBMXT_BAG_L2    0.810559  142  40  21  119  0.871166  0.748428   \n",
      "6     ExtraTreesEntr_BAG_L2    0.807453  139  38  24  121  0.852761  0.761006   \n",
      "7     ExtraTreesGini_BAG_L2    0.807453  142  41  21  118  0.871166  0.742138   \n",
      "8   RandomForestEntr_BAG_L1    0.795031  142  45  21  114  0.871166  0.716981   \n",
      "9     ExtraTreesEntr_BAG_L1    0.795031  143  46  20  113  0.877301  0.710692   \n",
      "10  RandomForestGini_BAG_L1    0.795031  145  48  18  111  0.889571  0.698113   \n",
      "11           XGBoost_BAG_L2    0.795031  139  42  24  117  0.852761  0.735849   \n",
      "12    NeuralNetTorch_BAG_L2    0.795031  138  41  25  118  0.846626  0.742138   \n",
      "13      WeightedEnsemble_L2    0.788820  134  39  29  120  0.822086  0.754717   \n",
      "14    ExtraTreesGini_BAG_L1    0.785714  142  48  21  111  0.871166  0.698113   \n",
      "15          LightGBM_BAG_L1    0.785714  133  39  30  120  0.815951  0.754717   \n",
      "16        LightGBMXT_BAG_L1    0.785714  133  39  30  120  0.815951  0.754717   \n",
      "17          CatBoost_BAG_L1    0.785714  137  43  26  116  0.840491  0.729560   \n",
      "18   NeuralNetFastAI_BAG_L1    0.782609  142  49  21  110  0.871166  0.691824   \n",
      "19   NeuralNetFastAI_BAG_L2    0.782609  144  51  19  108  0.883436  0.679245   \n",
      "20      WeightedEnsemble_L3    0.776398  144  53  19  106  0.883436  0.666667   \n",
      "21          LightGBM_BAG_L2    0.776398  144  53  19  106  0.883436  0.666667   \n",
      "22     LightGBMLarge_BAG_L2    0.776398  140  49  23  110  0.858896  0.691824   \n",
      "23    NeuralNetTorch_BAG_L1    0.773292  144  54  19  105  0.883436  0.660377   \n",
      "\n",
      "         Acc       MCC  score_val  pred_time_test  pred_time_val   fit_time  \\\n",
      "0   0.826087  0.653115   0.690838        5.020288      11.060572  57.250530   \n",
      "1   0.819876  0.640657   0.687465        4.502191      11.580020  52.921839   \n",
      "2   0.816770  0.639416   0.679033        0.140634       0.156144   6.545994   \n",
      "3   0.813665  0.629258   0.680157        0.075343       0.062385   2.688101   \n",
      "4   0.810559  0.621213   0.684654        4.533444      11.576764  53.000172   \n",
      "5   0.810559  0.624884   0.693086        4.549070      10.326794  53.719027   \n",
      "6   0.807453  0.616773   0.685779        4.517809      11.592507  52.906472   \n",
      "7   0.807453  0.619064   0.677347        4.517817      11.608235  52.875220   \n",
      "8   0.795031  0.595923   0.675660        0.074689       1.359471   1.218771   \n",
      "9   0.795031  0.597045   0.675098        0.078121       1.364540   1.203266   \n",
      "10  0.795031  0.599601   0.676223        0.084079       1.359470   1.312478   \n",
      "11  0.795031  0.593159   0.684092        4.533443      10.326802  54.437663   \n",
      "12  0.795031  0.592433   0.691962        4.564372      10.348961  62.484596   \n",
      "13  0.788820  0.578367   0.684654        0.681927       0.921207  13.962546   \n",
      "14  0.785714  0.578700   0.676223        0.078131       1.421975   1.265717   \n",
      "15  0.785714  0.571960   0.683530        0.109382       0.125013   2.031394   \n",
      "16  0.785714  0.571960   0.683530        0.109384       0.109390   2.062647   \n",
      "17  0.785714  0.574018   0.673412        0.562540       0.811818  11.187184   \n",
      "18  0.782609  0.572981   0.662732        3.030238       3.358316  12.203997   \n",
      "19  0.782609  0.575619   0.683530        7.424535      13.591192  64.210181   \n",
      "20  0.776398  0.564349   0.698145        4.549070      10.326792  54.826587   \n",
      "21  0.776398  0.564349   0.698145        4.549070      10.326792  54.094059   \n",
      "22  0.776398  0.559199   0.677347        4.595948      10.337695  59.344743   \n",
      "23  0.773292  0.558725   0.670039        0.097145       0.104516   9.999338   \n",
      "\n",
      "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0                  0.580601                0.827535           5.531645   \n",
      "1                  0.062504                1.346983           1.202953   \n",
      "2                  0.140634                0.156144           6.545994   \n",
      "3                  0.075343                0.062385           2.688101   \n",
      "4                  0.093757                1.343727           1.281286   \n",
      "5                  0.109383                0.093757           2.000141   \n",
      "6                  0.078122                1.359470           1.187586   \n",
      "7                  0.078130                1.375197           1.156334   \n",
      "8                  0.074689                1.359471           1.218771   \n",
      "9                  0.078121                1.364540           1.203266   \n",
      "10                 0.084079                1.359470           1.312478   \n",
      "11                 0.093756                0.093764           2.718777   \n",
      "12                 0.124685                0.115924          10.765710   \n",
      "13                 0.010004                0.000000           0.712716   \n",
      "14                 0.078131                1.421975           1.265717   \n",
      "15                 0.109382                0.125013           2.031394   \n",
      "16                 0.109384                0.109390           2.062647   \n",
      "17                 0.562540                0.811818          11.187184   \n",
      "18                 3.030238                3.358316          12.203997   \n",
      "19                 2.984848                3.358154          12.491295   \n",
      "20                 0.000000                0.000000           0.732528   \n",
      "21                 0.109383                0.093754           2.375173   \n",
      "22                 0.156261                0.104658           7.625858   \n",
      "23                 0.097145                0.104516           9.999338   \n",
      "\n",
      "    stack_level  can_infer  fit_order  \n",
      "0             2       True         17  \n",
      "1             2       True         16  \n",
      "2             1       True         11  \n",
      "3             1       True          9  \n",
      "4             2       True         15  \n",
      "5             2       True         13  \n",
      "6             2       True         19  \n",
      "7             2       True         18  \n",
      "8             1       True          4  \n",
      "9             1       True          7  \n",
      "10            1       True          3  \n",
      "11            2       True         21  \n",
      "12            2       True         22  \n",
      "13            2       True         12  \n",
      "14            1       True          6  \n",
      "15            1       True          2  \n",
      "16            1       True          1  \n",
      "17            1       True          5  \n",
      "18            1       True          8  \n",
      "19            2       True         20  \n",
      "20            3       True         24  \n",
      "21            2       True         14  \n",
      "22            2       True         23  \n",
      "23            1       True         10  \n",
      "\n",
      "MODELS EVALUATED\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "                               NOW PERFORMING RUN 5\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Developmental toxicity 5/Models/\n",
      "C:/Users/mwhw3/Desktop/DART project/AutoML models/V2.0.1 Reproductive toxicity 5/Data/V2.0.1 Reproductive toxicity 5 CSV test.csv\n",
      "\n",
      "SETTING UP DATA FOR MODEL...\n",
      "\n",
      "dat_test no. of SMILES:\n",
      "322\n",
      "322\n",
      "\n",
      "DATA SET UP FOR MODEL\n",
      "                      model  score_test   TP  FP  FN   TN        SE        SP  \\\n",
      "0     ExtraTreesEntr_BAG_L2    0.819876  136  30  28  128  0.829268  0.810127   \n",
      "1     NeuralNetTorch_BAG_L2    0.819876  136  30  28  128  0.829268  0.810127   \n",
      "2           CatBoost_BAG_L2    0.816770  132  27  32  131  0.804878  0.829114   \n",
      "3       WeightedEnsemble_L3    0.816770  132  27  32  131  0.804878  0.829114   \n",
      "4   RandomForestEntr_BAG_L2    0.813665  133  29  31  129  0.810976  0.816456   \n",
      "5   RandomForestGini_BAG_L1    0.810559  141  38  23  120  0.859756  0.759494   \n",
      "6   RandomForestEntr_BAG_L1    0.810559  139  36  25  122  0.847561  0.772152   \n",
      "7   RandomForestGini_BAG_L2    0.810559  134  31  30  127  0.817073  0.803797   \n",
      "8     ExtraTreesGini_BAG_L2    0.810559  135  32  29  126  0.823171  0.797468   \n",
      "9       WeightedEnsemble_L2    0.804348  137  36  27  122  0.835366  0.772152   \n",
      "10           XGBoost_BAG_L2    0.804348  133  32  31  126  0.810976  0.797468   \n",
      "11        LightGBMXT_BAG_L2    0.804348  134  33  30  125  0.817073  0.791139   \n",
      "12     LightGBMLarge_BAG_L1    0.801242  140  40  24  118  0.853659  0.746835   \n",
      "13    ExtraTreesEntr_BAG_L1    0.798137  138  39  26  119  0.841463  0.753165   \n",
      "14        LightGBMXT_BAG_L1    0.798137  136  37  28  121  0.829268  0.765823   \n",
      "15          LightGBM_BAG_L1    0.798137  136  37  28  121  0.829268  0.765823   \n",
      "16          LightGBM_BAG_L2    0.795031  136  38  28  120  0.829268  0.759494   \n",
      "17    ExtraTreesGini_BAG_L1    0.791925  137  40  27  118  0.835366  0.746835   \n",
      "18           XGBoost_BAG_L1    0.779503  136  43  28  115  0.829268  0.727848   \n",
      "19     LightGBMLarge_BAG_L2    0.779503  132  39  32  119  0.804878  0.753165   \n",
      "20          CatBoost_BAG_L1    0.770186  134  44  30  114  0.817073  0.721519   \n",
      "21   NeuralNetFastAI_BAG_L2    0.763975  137  49  27  109  0.835366  0.689873   \n",
      "22    NeuralNetTorch_BAG_L1    0.760870  135  48  29  110  0.823171  0.696203   \n",
      "23   NeuralNetFastAI_BAG_L1    0.751553  136  52  28  106  0.829268  0.670886   \n",
      "\n",
      "         Acc       MCC  score_val  pred_time_test  pred_time_val   fit_time  \\\n",
      "0   0.819876  0.639592   0.695897        4.562817      11.523492  50.522113   \n",
      "1   0.819876  0.639592   0.703766        4.578442      10.289026  55.990769   \n",
      "2   0.816770  0.633931   0.713884        5.125358      11.007830  53.803715   \n",
      "3   0.816770  0.633931   0.714446        5.234740      11.085955  56.448406   \n",
      "4   0.813665  0.627334   0.693648        4.562816      11.539117  50.428201   \n",
      "5   0.810559  0.623048   0.683530        0.078130       1.375096   1.203153   \n",
      "6   0.810559  0.621961   0.676785        0.078130       1.359359   1.249959   \n",
      "7   0.810559  0.620955   0.700956        4.547191      11.523491  50.412803   \n",
      "8   0.810559  0.620963   0.689151        4.562816      11.523488  50.412750   \n",
      "9   0.804348  0.609107   0.715008        4.156547       9.913654  34.981164   \n",
      "10  0.804348  0.608526   0.704328        4.578443      10.242146  51.162756   \n",
      "11  0.804348  0.608530   0.702642        4.594069      10.257769  51.100399   \n",
      "12  0.801242  0.604615   0.690838        0.140634       0.140634   6.661024   \n",
      "13  0.798137  0.597482   0.689713        0.078122       1.359360   1.218837   \n",
      "14  0.798137  0.596647   0.697021        0.125009       0.125017   2.312663   \n",
      "15  0.798137  0.596647   0.697021        0.140635       0.109378   2.437673   \n",
      "16  0.795031  0.590588   0.711636        4.594070      10.289026  51.600433   \n",
      "17  0.791925  0.584996   0.690275        0.078131       1.367657   1.218813   \n",
      "18  0.779503  0.560534   0.690838        0.078130       0.046880   2.562681   \n",
      "19  0.779503  0.559025   0.701518        4.594069      10.289028  55.240546   \n",
      "20  0.770186  0.541526   0.685779        0.625045       0.812552   8.344342   \n",
      "21  0.763975  0.531596   0.664418        7.453649      13.585538  61.356530   \n",
      "22  0.760870  0.524200   0.687465        0.109375       0.109734   9.952960   \n",
      "23  0.751553  0.507251   0.680720        2.953346       3.373979  12.063158   \n",
      "\n",
      "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0                  0.078131                1.343845           1.296848   \n",
      "1                  0.093756                0.109380           6.765504   \n",
      "2                  0.640672                0.828183           4.578450   \n",
      "3                  0.015626                0.015626           0.707200   \n",
      "4                  0.078130                1.359470           1.202936   \n",
      "5                  0.078130                1.375096           1.203153   \n",
      "6                  0.078130                1.359359           1.249959   \n",
      "7                  0.062505                1.343844           1.187538   \n",
      "8                  0.078130                1.343842           1.187485   \n",
      "9                  0.000000                0.000000           0.709213   \n",
      "10                 0.093757                0.062499           1.937491   \n",
      "11                 0.109383                0.078123           1.875134   \n",
      "12                 0.140634                0.140634           6.661024   \n",
      "13                 0.078122                1.359360           1.218837   \n",
      "14                 0.125009                0.125017           2.312663   \n",
      "15                 0.140635                0.109378           2.437673   \n",
      "16                 0.109384                0.109379           2.375168   \n",
      "17                 0.078131                1.367657           1.218813   \n",
      "18                 0.078130                0.046880           2.562681   \n",
      "19                 0.109383                0.109381           6.015281   \n",
      "20                 0.625045                0.812552           8.344342   \n",
      "21                 2.968963                3.405891          12.131265   \n",
      "22                 0.109375                0.109734           9.952960   \n",
      "23                 2.953346                3.373979          12.063158   \n",
      "\n",
      "    stack_level  can_infer  fit_order  \n",
      "0             2       True         19  \n",
      "1             2       True         22  \n",
      "2             2       True         17  \n",
      "3             3       True         24  \n",
      "4             2       True         16  \n",
      "5             1       True          3  \n",
      "6             1       True          4  \n",
      "7             2       True         15  \n",
      "8             2       True         18  \n",
      "9             2       True         12  \n",
      "10            2       True         21  \n",
      "11            2       True         13  \n",
      "12            1       True         11  \n",
      "13            1       True          7  \n",
      "14            1       True          1  \n",
      "15            1       True          2  \n",
      "16            2       True         14  \n",
      "17            1       True          6  \n",
      "18            1       True          9  \n",
      "19            2       True         23  \n",
      "20            1       True          5  \n",
      "21            2       True         20  \n",
      "22            1       True         10  \n",
      "23            1       True          8  \n",
      "\n",
      "MODELS EVALUATED\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "                         ALL MODELS EVALUATED WITH TEST SET(S)\n",
      "\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "#=========================================================================================#\n",
      "\n",
      "#=========================================================================================#\n",
      "\n",
      "                                 DATAFRAME OF MEANS\n",
      "\n",
      "#=========================================================================================#\n",
      "\n",
      "                           SE    SP   Acc    MCC\n",
      "model                                           \n",
      "CatBoost_BAG_L1          85.5  92.4  88.8  0.779\n",
      "CatBoost_BAG_L2          95.2  96.2  95.7  0.914\n",
      "ExtraTreesEntr_BAG_L1    95.6  95.9  95.7  0.914\n",
      "ExtraTreesEntr_BAG_L2    93.0  95.6  94.2  0.885\n",
      "ExtraTreesGini_BAG_L1    95.6  95.8  95.7  0.914\n",
      "ExtraTreesGini_BAG_L2    93.0  95.8  94.3  0.887\n",
      "LightGBMLarge_BAG_L1     94.6  94.7  94.6  0.893\n",
      "LightGBMLarge_BAG_L2     93.9  93.9  93.9  0.878\n",
      "LightGBMXT_BAG_L1        87.7  90.9  89.2  0.785\n",
      "LightGBMXT_BAG_L2        94.1  95.2  94.6  0.892\n",
      "LightGBM_BAG_L1          87.7  90.9  89.2  0.785\n",
      "LightGBM_BAG_L2          94.2  94.5  94.3  0.886\n",
      "NeuralNetFastAI_BAG_L1   94.7  94.3  94.5  0.891\n",
      "NeuralNetFastAI_BAG_L2   94.6  95.2  94.9  0.897\n",
      "NeuralNetTorch_BAG_L1    91.0  94.6  92.7  0.855\n",
      "NeuralNetTorch_BAG_L2    91.8  96.3  93.9  0.879\n",
      "RandomForestEntr_BAG_L1  95.7  96.1  95.9  0.918\n",
      "RandomForestEntr_BAG_L2  94.3  95.8  95.0    0.9\n",
      "RandomForestGini_BAG_L1  95.7  96.0  95.8  0.916\n",
      "RandomForestGini_BAG_L2  94.5  95.8  95.1  0.902\n",
      "WeightedEnsemble_L2      94.0  95.6  94.8  0.896\n",
      "WeightedEnsemble_L3      93.8  95.4  94.5  0.891\n",
      "XGBoost_BAG_L1           84.2  92.5  88.1  0.766\n",
      "XGBoost_BAG_L2           94.2  95.1  94.6  0.893\n",
      "\n",
      "#=========================================================================================#\n",
      "\n",
      "                                 DATAFRAME OF STD\n",
      "\n",
      "#=========================================================================================#\n",
      "\n",
      "                          SE   SP  Acc    MCC\n",
      "model                                        \n",
      "CatBoost_BAG_L1          1.9  1.7  1.8  0.036\n",
      "CatBoost_BAG_L2          0.5  0.8  0.5  0.009\n",
      "ExtraTreesEntr_BAG_L1    0.5  0.7  0.3  0.006\n",
      "ExtraTreesEntr_BAG_L2    0.5  0.7  0.2  0.005\n",
      "ExtraTreesGini_BAG_L1    0.5  0.8  0.4  0.008\n",
      "ExtraTreesGini_BAG_L2    0.7  0.6  0.4  0.007\n",
      "LightGBMLarge_BAG_L1     1.1  1.6  1.3  0.026\n",
      "LightGBMLarge_BAG_L2     0.3  1.4  0.7  0.014\n",
      "LightGBMXT_BAG_L1        2.2  2.3  2.1  0.043\n",
      "LightGBMXT_BAG_L2        1.7  0.8  1.2  0.024\n",
      "LightGBM_BAG_L1          2.2  2.3  2.1  0.043\n",
      "LightGBM_BAG_L2          1.3  1.3  1.1  0.023\n",
      "NeuralNetFastAI_BAG_L1   1.4  0.6  0.8  0.015\n",
      "NeuralNetFastAI_BAG_L2   0.4  0.8  0.4  0.007\n",
      "NeuralNetTorch_BAG_L1    2.6  0.9  1.5  0.029\n",
      "NeuralNetTorch_BAG_L2    1.4  0.9  0.6  0.011\n",
      "RandomForestEntr_BAG_L1  0.7  0.8  0.4  0.009\n",
      "RandomForestEntr_BAG_L2  0.6  0.6  0.2  0.004\n",
      "RandomForestGini_BAG_L1  0.7  0.6  0.3  0.006\n",
      "RandomForestGini_BAG_L2  0.3  0.5  0.2  0.004\n",
      "WeightedEnsemble_L2      3.4  0.8  2.0  0.039\n",
      "WeightedEnsemble_L3      1.8  1.2  1.3  0.027\n",
      "XGBoost_BAG_L1           2.5  1.5  2.0  0.039\n",
      "XGBoost_BAG_L2           0.4  1.3  0.8  0.017\n",
      "\n",
      "#=========================================================================================#\n",
      "\n",
      "                                 OVERALL DATAFRAME\n",
      "\n",
      "#=========================================================================================#\n",
      "\n",
      "                                 SE          SP         Acc            MCC\n",
      "model                                                                     \n",
      "CatBoost_BAG_L1          85.5 ± 1.9  92.4 ± 1.7  88.8 ± 1.8  0.779 ± 0.036\n",
      "CatBoost_BAG_L2          95.2 ± 0.5  96.2 ± 0.8  95.7 ± 0.5  0.914 ± 0.009\n",
      "ExtraTreesEntr_BAG_L1    95.6 ± 0.5  95.9 ± 0.7  95.7 ± 0.3  0.914 ± 0.006\n",
      "ExtraTreesEntr_BAG_L2    93.0 ± 0.5  95.6 ± 0.7  94.2 ± 0.2  0.885 ± 0.005\n",
      "ExtraTreesGini_BAG_L1    95.6 ± 0.5  95.8 ± 0.8  95.7 ± 0.4  0.914 ± 0.008\n",
      "ExtraTreesGini_BAG_L2    93.0 ± 0.7  95.8 ± 0.6  94.3 ± 0.4  0.887 ± 0.007\n",
      "LightGBMLarge_BAG_L1     94.6 ± 1.1  94.7 ± 1.6  94.6 ± 1.3  0.893 ± 0.026\n",
      "LightGBMLarge_BAG_L2     93.9 ± 0.3  93.9 ± 1.4  93.9 ± 0.7  0.878 ± 0.014\n",
      "LightGBMXT_BAG_L1        87.7 ± 2.2  90.9 ± 2.3  89.2 ± 2.1  0.785 ± 0.043\n",
      "LightGBMXT_BAG_L2        94.1 ± 1.7  95.2 ± 0.8  94.6 ± 1.2  0.892 ± 0.024\n",
      "LightGBM_BAG_L1          87.7 ± 2.2  90.9 ± 2.3  89.2 ± 2.1  0.785 ± 0.043\n",
      "LightGBM_BAG_L2          94.2 ± 1.3  94.5 ± 1.3  94.3 ± 1.1  0.886 ± 0.023\n",
      "NeuralNetFastAI_BAG_L1   94.7 ± 1.4  94.3 ± 0.6  94.5 ± 0.8  0.891 ± 0.015\n",
      "NeuralNetFastAI_BAG_L2   94.6 ± 0.4  95.2 ± 0.8  94.9 ± 0.4  0.897 ± 0.007\n",
      "NeuralNetTorch_BAG_L1    91.0 ± 2.6  94.6 ± 0.9  92.7 ± 1.5  0.855 ± 0.029\n",
      "NeuralNetTorch_BAG_L2    91.8 ± 1.4  96.3 ± 0.9  93.9 ± 0.6  0.879 ± 0.011\n",
      "RandomForestEntr_BAG_L1  95.7 ± 0.7  96.1 ± 0.8  95.9 ± 0.4  0.918 ± 0.009\n",
      "RandomForestEntr_BAG_L2  94.3 ± 0.6  95.8 ± 0.6  95.0 ± 0.2    0.9 ± 0.004\n",
      "RandomForestGini_BAG_L1  95.7 ± 0.7  96.0 ± 0.6  95.8 ± 0.3  0.916 ± 0.006\n",
      "RandomForestGini_BAG_L2  94.5 ± 0.3  95.8 ± 0.5  95.1 ± 0.2  0.902 ± 0.004\n",
      "WeightedEnsemble_L2      94.0 ± 3.4  95.6 ± 0.8  94.8 ± 2.0  0.896 ± 0.039\n",
      "WeightedEnsemble_L3      93.8 ± 1.8  95.4 ± 1.2  94.5 ± 1.3  0.891 ± 0.027\n",
      "XGBoost_BAG_L1           84.2 ± 2.5  92.5 ± 1.5  88.1 ± 2.0  0.766 ± 0.039\n",
      "XGBoost_BAG_L2           94.2 ± 0.4  95.1 ± 1.3  94.6 ± 0.8  0.893 ± 0.017\n",
      "\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "# Code for using trained models to predict on an external test set or external data\n",
    "\n",
    "# Author: Marcus Wei How Wang\n",
    "# 5 May 2022\n",
    "\n",
    "#======================================================================================#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from os.path import isfile\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "import pickle\n",
    "from random import randrange\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "#======================================================================================#\n",
    "# This function gets the Morgan fingeprint given a SMILES dataframe and specified fingerprint parameters\n",
    "def get_Morgan_fingerprint(smiles,nBits,fingerprint_radius):\n",
    "    \n",
    "    '''smiles dataframe'''\n",
    "    error_idx_ls =[]\n",
    "    error_idx_ls.clear()\n",
    "    \n",
    "    rdkit_molecules=[Chem.MolFromSmiles(x) for x in smiles]\n",
    "    print(len(rdkit_molecules))\n",
    "    rdkit_fingerprint=[]\n",
    "    count = 0\n",
    "    fingerprint_length = int(nBits)\n",
    "    #print(rdkit_molecules[:1])\n",
    "    for mol in rdkit_molecules:\n",
    "        # if count % 1000 == 0:\n",
    "        #     print('Now fingerprinting {} of {}'.format(count,len(rdkit_molecules)))\n",
    "        bit_info={}\n",
    "        try:\n",
    "            fp=rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=fingerprint_radius, nBits=fingerprint_length,\n",
    "                                                          bitInfo=bit_info)\n",
    "        except:\n",
    "            # get indexes of errors with errors\n",
    "            error_idx_ls.append(rdkit_molecules.index(mol))\n",
    "\n",
    "        rdkit_fingerprint.append(fp)\n",
    "        count += 1\n",
    "        \n",
    "    fingerprint_df=pd.DataFrame([np.array(list(x)).astype(int) for x in rdkit_fingerprint])\n",
    "    #fingerprint_df = pd.DataFrame(rdkit_fingerprint,columns=['BV'])\n",
    "    \n",
    "    return fingerprint_df, error_idx_ls\n",
    "\n",
    "def get_MACCS_fingerprint(smiles):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fingerprint_df\n",
    "\n",
    "\n",
    "# This function is expecting a input csv with two columns 'SMILES' and 'Binary Activity'\n",
    "def split_train_test(csv,test_ratio,train_save,test_save,overwrite):\n",
    "    \n",
    "    # Read input and shuffle randomly\n",
    "    input_df = pd.read_csv(csv)\n",
    "    print(input_df)\n",
    "    input_df = input_df.sample(frac=1)\n",
    "    input_np = input_df.to_numpy()\n",
    "    \n",
    "    # split df randomly according to specified ratio\n",
    "    train_df, test_df = train_test_split(input_np, test_size=test_ratio)\n",
    "    \n",
    "    train_df = pd.DataFrame(train_df,columns=['SMILES','Binary Activity'])\n",
    "    test_df = pd.DataFrame(test_df,columns=['SMILES','Binary Activity'])\n",
    "    \n",
    "    # Save files\n",
    "    # Ovewrite existing file present in folder\n",
    "#     print(isfile(train_save))\n",
    "#     print(isfile(test_save))\n",
    "    if overwrite == False and isfile(train_save) == True:\n",
    "        train_save = train_save[:-4] + str(randrange(100)) + train_save[-4:]\n",
    "        train_df.to_csv(train_save)        \n",
    "    else:\n",
    "        train_df.to_csv(train_save)\n",
    "    \n",
    "    if overwrite == False and isfile(test_save) == True:\n",
    "        test_save = test_save[:-4] + str(randrange(100)) + test_save[-4:]\n",
    "        test_df.to_csv(test_save)        \n",
    "    else:\n",
    "        test_df.to_csv(test_save)\n",
    "    \n",
    "    \n",
    "    return train_save,test_save\n",
    "\n",
    "def most_probable_class(column_list):\n",
    "    col_val = set(column_list)\n",
    "    most_prob_class_count = 0\n",
    "    most_prob_class = 0\n",
    "    for ele in col_val:\n",
    "        class_count = column_list.count(ele)\n",
    "        if class_count > most_prob_class_count:\n",
    "            most_prob_class_count = class_count\n",
    "            most_prob_class = ele\n",
    "            \n",
    "    return most_prob_class\n",
    "\n",
    "\n",
    "def calc_baseline_acc(df_column_list):\n",
    "    \n",
    "    # Baseline accuracy is the accuracy when all the predicted classes are the most probable class\n",
    "    baseline_class = most_probable_class(df_column_list)\n",
    "    baseline_acc = df_column_list.count(baseline_class) / len(df_column_list) * 100\n",
    "    \n",
    "    print('Baseline accuracy:')\n",
    "    print(baseline_acc)\n",
    "    \n",
    "    return baseline_acc\n",
    "\n",
    "def acc(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "def sensitivity(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tp)/(tp+fn)\n",
    "\n",
    "def specificity(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tn)/(fp+tn)\n",
    "\n",
    "def tp_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return tp\n",
    "\n",
    "def fn_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # Needs the - sign since predictor.leaderboard flips the sign\n",
    "    return -fn  \n",
    "\n",
    "def fp_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # Needs the - sign since predictor.leaderboard flips the sign\n",
    "    return -fp  \n",
    "\n",
    "def tn_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return tn  \n",
    "\n",
    "\n",
    "def create_AutoGluon_extra_metrics(y_test,y_pred):\n",
    "    from autogluon.core.metrics import make_scorer\n",
    "    # Score functions need to have the definition:\n",
    "    # score_func(y, y_pred, **kwargs)\n",
    "    # Otherwise the calculations of the metrics will fail\n",
    "    \n",
    "    metrics_ls = []\n",
    "    metrics_ls.clear()\n",
    "    \n",
    "    # Calculate confusion matrix for custom metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    MCC = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "      \n",
    "    # Define custom scoring functions to pass to predictor.leaderboard()\n",
    "    ag_accuracy_scorer = make_scorer(name='Acc',\n",
    "                                 score_func=acc,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    ag_mcc_scorer = make_scorer(name='MCC',\n",
    "                                 score_func=matthews_corrcoef,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    ag_sensitivity_scorer = make_scorer(name='SE',\n",
    "                                 score_func=sensitivity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "\n",
    "    ag_specificity_scorer = make_scorer(name='SP',\n",
    "                                 score_func=specificity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "  \n",
    "    tn_scorer = make_scorer(name='TN',score_func=tn_func,greater_is_better=True)\n",
    "\n",
    "    \n",
    "      \n",
    "    fp_scorer = make_scorer(name='FP',score_func=fp_func,greater_is_better=False)\n",
    "\n",
    "    \n",
    "      \n",
    "    fn_scorer = make_scorer(name='FN',score_func=fn_func,greater_is_better=False)\n",
    "\n",
    "    \n",
    "\n",
    "    tp_scorer = make_scorer(name='TP',score_func=tp_func,greater_is_better=True)\n",
    "\n",
    "    \n",
    "    # Append all metrics to list\n",
    "    metrics_ls.append(tp_scorer)\n",
    "    metrics_ls.extend((fp_scorer, fn_scorer, tn_scorer, ag_sensitivity_scorer,\n",
    "                      ag_specificity_scorer, ag_accuracy_scorer, ag_mcc_scorer))\n",
    "#     print(metrics_ls)\n",
    "    return metrics_ls\n",
    "#======================================================================================#\n",
    "def AutoGluon(training_set,test_set,save_path,model_results,model_name):\n",
    "    print('\\nSETTING UP DATA FOR MODEL...')\n",
    "    dat_train = pd.read_csv(training_set, sep=',')\n",
    "    dat_train_smi = dat_train['SMILES'].tolist()\n",
    "    print('\\ndat_train no. of SMILES:')\n",
    "    print(len(dat_train_smi))\n",
    "\n",
    "    y_train = dat_train[['Binary Activity']]\n",
    "    X_train,error_idx_ls = get_Morgan_fingerprint(dat_train_smi,2048,2)\n",
    "\n",
    "    y_train = y_train.drop(error_idx_ls)\n",
    "    X_train = X_train.drop(error_idx_ls)\n",
    "\n",
    "    dat_test = pd.read_csv(test_set, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    y_test = dat_test[['Binary Activity']]\n",
    "    X_test,error_idx_ls = get_Morgan_fingerprint(dat_test_smi,2048,2)\n",
    "\n",
    "    # Drop rows with errors\n",
    "    y_test = y_test.drop(error_idx_ls)\n",
    "    X_test = X_test.drop(error_idx_ls)\n",
    "\n",
    "    print(X_train)\n",
    "    print(y_train)\n",
    "\n",
    "    print('\\nDATA SET UP FOR MODEL')\n",
    "    \n",
    "    print('\\nPREPARING AND TRAINING MODELS...')\n",
    "    # The dataframes need to be converted to the object used byu the AutoGluon package\n",
    "    label = 'Binary Activity'\n",
    "    train_data = TabularDataset(pd.concat([X_train,y_train],axis=1))\n",
    "    \n",
    "    # This the maximum time limit in seconds for each set of models\n",
    "    # Essentially, this means the models will take an estimated (13 * time_limit * (num_stack_levels +1)) \n",
    "    # amount of seconds to train. Note training time is also affected by the preset quality\n",
    "    time_limit = 60 * 60\n",
    "    metric = 'accuracy'\n",
    "    \n",
    "    # Best quality focuses on acc but takes longer to run. For more details see the package documentation\n",
    "    preset = 'best_quality'\n",
    "    \n",
    "    # add hyperparameter_tune_kwargs if necessary\n",
    "#     num_trials = 25  # try at most n different hyperparameter configurations for each type of model\n",
    "#     search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "#     hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#         'num_trials': num_trials,\n",
    "#         'scheduler' : 'local',\n",
    "#         'searcher': search_strategy,\n",
    "#     }\n",
    "    \n",
    "    \n",
    "    # Model ensembling with stacking/bagging\n",
    "    # According to the documentation, \"beyond hyperparameter-tuning with a correctly-specified evaluation metric,\n",
    "    # two other methods to boost predictive performance are bagging and stack-ensembling. \n",
    "    # You’ll often see performance improve if you specify num_bag_folds = 5-10, \n",
    "    # num_stack_levels = 1-3 in the call to fit(), but this will increase training times and memory/disk usage.\"\n",
    "    # By default no hyperparameter optimisation is done ie. when hyperparameter_tune_kwargs is not specified\n",
    "    predictor = TabularPredictor(label, eval_metric=metric,path=model_name).fit(train_data,num_bag_folds=5, \n",
    "                                                                num_bag_sets=1, num_stack_levels=1, \n",
    "                                                                time_limit=time_limit,\n",
    "                                                                presets=preset\n",
    "#                                                                ,hyperparameter_tune_kwargs=hyperparameter_tune_kwargs\n",
    "                                                               )\n",
    "                                                               \n",
    "    print('\\nMODELS TRAINED')\n",
    "    \n",
    "    print('\\nEVALUATING MODELS...')\n",
    "    test_data = TabularDataset(pd.concat([X_test,y_test],axis=1))\n",
    "    y_test = test_data[label]  # values to predict\n",
    "    X_test = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "    X_test.head()\n",
    "    \n",
    "    y_pred = predictor.predict(X_test)\n",
    "    #print(\"Predictions:  \\n\", y_pred)\n",
    "    #perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n",
    "    \n",
    "    #print(\"TRUE VALUES:  \\n\", y_test)\n",
    "    y_test = y_test.tolist()\n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    add_metrics = create_AutoGluon_extra_metrics(y_test,y_pred)\n",
    "\n",
    "    results_df = predictor.leaderboard(test_data, silent=True,\n",
    "                                       extra_metrics=add_metrics\n",
    "                                      )\n",
    "    results_df.to_csv(model_results)\n",
    "    print(results_df)\n",
    "    print('\\nMODELS EVALUATED')   \n",
    "    \n",
    "    return\n",
    "\n",
    "def set_up_test_data(test_path):\n",
    "    print('\\nSETTING UP DATA FOR MODEL...')\n",
    "\n",
    "    dat_test = pd.read_csv(test_path, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    y_test = dat_test[['Binary Activity']]\n",
    "    X_test,error_idx_ls = get_Morgan_fingerprint(dat_test_smi,2048,2)\n",
    "\n",
    "    # Drop rows with errors\n",
    "    y_test = y_test.drop(error_idx_ls)\n",
    "    \n",
    "    X_test = X_test.drop(error_idx_ls)\n",
    "\n",
    "    print('\\nDATA SET UP FOR MODEL')\n",
    "    \n",
    "    return X_test,y_test\n",
    "    \n",
    "\n",
    "\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "# Set filepaths for functions\n",
    "\n",
    "# Filename of model to load'\n",
    "# model_root_desc = 'V2.0.1 Unified data'\n",
    "model_root_desc = 'V2.0.1 Developmental toxicity'\n",
    "# model_root_desc = 'V2.0.1 Reproductive toxicity'\n",
    "\n",
    "# Filepath of test csv containing two columsn 'SMILES' and 'Binary Activity'\n",
    "root_desc = 'V2.0.1 Reproductive toxicity'\n",
    "# root_desc = 'V2.0.1 Developmental toxicity'\n",
    "\n",
    "root = 'C:/Users/mwhw3/Desktop/DART project/'\n",
    "# test_path = root + root_desc + '.csv'\n",
    "\n",
    "total_runs = 5\n",
    "\n",
    "overall_save = root + 'Transfer learning/' + root_desc + ' ' + model_root_desc + ' dev_to_repro_test_2 ' + \\\n",
    "str(total_runs) +' runs.csv'\n",
    "#overall_save = root + 'AutoML models combined results/' + root_desc + ' ' + str(total_runs) +' runs.csv'\n",
    "\n",
    "for run in range(1,total_runs+1):\n",
    "    \n",
    "    print('\\n#=========================================================================================#')\n",
    "    print('#=========================================================================================#')\n",
    "    print('\\n                               NOW PERFORMING RUN {}\\n'.format(run))\n",
    "    print('#=========================================================================================#')\n",
    "    print('#=========================================================================================#')\n",
    "    \n",
    "    desc = root_desc + ' ' + str(run)\n",
    "    model_desc = model_root_desc + ' ' + str(run)\n",
    "    \n",
    "    # Load location for models\n",
    "    model_name = root + 'AutoML models/' + model_desc + '/' + 'Models/'\n",
    "    print(model_name)\n",
    "\n",
    "    # Save location for models results\n",
    "    check_path = root + 'Transfer learning/' + desc + '/' + 'Results/'\n",
    "    if os.path.exists(check_path)== False:\n",
    "        os.makedirs(check_path)\n",
    "        \n",
    "    model_results = root + 'Transfer learning/' + desc + '/' + 'Results/' + desc + ' model results_2.csv'\n",
    "    \n",
    "    test_path = root + 'AutoML models/' + root_desc + ' ' + str(run) + '/Data/' + \\\n",
    "    root_desc + ' ' + str(run) + ' CSV test.csv'\n",
    "    print(test_path)\n",
    "    \n",
    "    # Set up test data\n",
    "    X_test,y_test = set_up_test_data(test_path)\n",
    "    test_data = TabularDataset(pd.concat([X_test,y_test],axis=1))\n",
    "    y_test = y_test['Binary Activity'].tolist()\n",
    "    \n",
    "    #==============================================================================================#                             \n",
    "\n",
    "    # Load predictor   \n",
    "    predictor = TabularPredictor.load(model_name)\n",
    "    y_pred = predictor.predict(X_test)\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    add_metrics = create_AutoGluon_extra_metrics(y_test,y_pred)\n",
    "\n",
    "    results_df = predictor.leaderboard(test_data, silent=True,\n",
    "                                       extra_metrics=add_metrics\n",
    "                                      )\n",
    "    results_df.to_csv(model_results)\n",
    "    print(results_df)\n",
    "    print('\\nMODELS EVALUATED')\n",
    "    \n",
    "    \n",
    "print('\\n#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('\\n                         ALL MODELS EVALUATED WITH TEST SET(S)\\n'                          )\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "\n",
    "\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#    \n",
    "# Combine results for models across all runs    \n",
    "\n",
    "# Filepath of csv containing two columsn 'SMILES' and 'Binary Activity'\n",
    "\n",
    "\n",
    "\n",
    "#col_ls = ['TP','FP','FN','TN','SE','SP','Acc','MCC']\n",
    "col_ls = ['model','SE','SP','Acc','MCC']\n",
    "\n",
    "result_dict = {}\n",
    "result_dict.clear()\n",
    "for run in range(1,total_runs+1):\n",
    "    desc = root_desc + ' ' + str(run)\n",
    "    model_results = root + 'Transfer learning/' + desc + '/' + 'Results/' + desc + ' model results.csv'\n",
    "\n",
    "    results_df = pd.read_csv(model_results)\n",
    "\n",
    "    results_df = results_df[col_ls]\n",
    "    #print(results_df)\n",
    "    results_name = str(results_df) + str(run)\n",
    "    result_dict[results_name] = results_df\n",
    "\n",
    "    \n",
    "combined_df = pd.concat(result_dict.values(),ignore_index=True)\n",
    "\n",
    "\n",
    "mean_df = combined_df.groupby(by=['model']).mean()\n",
    "\n",
    "print('\\n#=========================================================================================#')\n",
    "print('\\n                                 DATAFRAME OF MEANS\\n'                                      )\n",
    "print('#=========================================================================================#\\n')\n",
    "\n",
    "mean_df['SE'] = 100 * mean_df['SE']\n",
    "mean_df['SP'] = 100 * mean_df['SP']\n",
    "mean_df['Acc'] = 100 * mean_df['Acc']\n",
    "\n",
    "mean_df = mean_df.round({'SE': 1,'SP': 1,'Acc': 1,'MCC': 3}).astype(str)\n",
    "print(mean_df)\n",
    "\n",
    "std_df = combined_df.groupby(by=['model']).agg(np.std)\n",
    "print('\\n#=========================================================================================#')\n",
    "print('\\n                                 DATAFRAME OF STD\\n'                                        )\n",
    "print('#=========================================================================================#\\n')\n",
    "\n",
    "std_df['SE'] = 100 * std_df['SE']\n",
    "std_df['SP'] = 100 * std_df['SP']\n",
    "std_df['Acc'] = 100 * std_df['Acc']\n",
    "\n",
    "std_df = std_df.round({'SE': 1,'SP': 1,'Acc': 1,'MCC': 3}).astype(str)\n",
    "print(std_df)\n",
    "\n",
    "# mean_df = mean_df.applymap(str)\n",
    "# print(mean_df)\n",
    "# std_df = std_df.applymap(str)\n",
    "overall_df = mean_df\n",
    "\n",
    "overall_df['SE'] = mean_df['SE'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['SE']\n",
    "overall_df['SP'] = mean_df['SP'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['SP']\n",
    "overall_df['Acc'] = mean_df['Acc'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['Acc']\n",
    "overall_df['MCC'] = mean_df['MCC'] + ' '+ str(u\"\\u00B1\") + ' ' + std_df['MCC']\n",
    "\n",
    "print('\\n#=========================================================================================#')\n",
    "print('\\n                                 OVERALL DATAFRAME\\n'                                        )\n",
    "print('#=========================================================================================#\\n')\n",
    "\n",
    "overall_df.to_csv(overall_save)\n",
    "print(overall_df)\n",
    "\n",
    "print('\\nFINISHED')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265928c8",
   "metadata": {},
   "source": [
    "# For loading choice of models on a set of new chemicals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61aedd",
   "metadata": {},
   "source": [
    "This code will load previously saved models and apply them to new chemicals (SMILES). The results can be returned as a dataframe containing the predicted asctivities/toxicity or as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2aaa1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code for using trained models to predict on an external test set or external data\n",
    "\n",
    "# Author: Marcus Wei How Wang\n",
    "# 5 May 2022\n",
    "\n",
    "#======================================================================================#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from os.path import isfile\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "import pickle\n",
    "from random import randrange\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "#======================================================================================#\n",
    "# This function gets the Morgan fingeprint given a SMILES dataframe and specified fingerprint parameters\n",
    "def get_Morgan_fingerprint(smiles,nBits,fingerprint_radius):\n",
    "    \n",
    "    '''smiles dataframe'''\n",
    "    error_idx_ls =[]\n",
    "    error_idx_ls.clear()\n",
    "    \n",
    "    rdkit_molecules=[Chem.MolFromSmiles(x) for x in smiles]\n",
    "    print(len(rdkit_molecules))\n",
    "    rdkit_fingerprint=[]\n",
    "    count = 0\n",
    "    fingerprint_length = int(nBits)\n",
    "    #print(rdkit_molecules[:1])\n",
    "    for mol in rdkit_molecules:\n",
    "        # if count % 1000 == 0:\n",
    "        #     print('Now fingerprinting {} of {}'.format(count,len(rdkit_molecules)))\n",
    "        bit_info={}\n",
    "        try:\n",
    "            fp=rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=fingerprint_radius, nBits=fingerprint_length,\n",
    "                                                          bitInfo=bit_info)\n",
    "        except:\n",
    "            # get indexes of errors with errors\n",
    "            error_idx_ls.append(rdkit_molecules.index(mol))\n",
    "\n",
    "        rdkit_fingerprint.append(fp)\n",
    "        count += 1\n",
    "        \n",
    "    fingerprint_df=pd.DataFrame([np.array(list(x)).astype(int) for x in rdkit_fingerprint])\n",
    "    #fingerprint_df = pd.DataFrame(rdkit_fingerprint,columns=['BV'])\n",
    "    \n",
    "    return fingerprint_df, error_idx_ls\n",
    "\n",
    "def get_MACCS_fingerprint(smiles):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fingerprint_df\n",
    "\n",
    "\n",
    "# This function is expecting a input csv with two columns 'SMILES' and 'Binary Activity'\n",
    "def split_train_test(csv,test_ratio,train_save,test_save,overwrite):\n",
    "    \n",
    "    # Read input and shuffle randomly\n",
    "    input_df = pd.read_csv(csv)\n",
    "    print(input_df)\n",
    "    input_df = input_df.sample(frac=1)\n",
    "    input_np = input_df.to_numpy()\n",
    "    \n",
    "    # split df randomly according to specified ratio\n",
    "    train_df, test_df = train_test_split(input_np, test_size=test_ratio)\n",
    "    \n",
    "    train_df = pd.DataFrame(train_df,columns=['SMILES','Binary Activity'])\n",
    "    test_df = pd.DataFrame(test_df,columns=['SMILES','Binary Activity'])\n",
    "    \n",
    "    # Save files\n",
    "    # Ovewrite existing file present in folder\n",
    "#     print(isfile(train_save))\n",
    "#     print(isfile(test_save))\n",
    "    if overwrite == False and isfile(train_save) == True:\n",
    "        train_save = train_save[:-4] + str(randrange(100)) + train_save[-4:]\n",
    "        train_df.to_csv(train_save)        \n",
    "    else:\n",
    "        train_df.to_csv(train_save)\n",
    "    \n",
    "    if overwrite == False and isfile(test_save) == True:\n",
    "        test_save = test_save[:-4] + str(randrange(100)) + test_save[-4:]\n",
    "        test_df.to_csv(test_save)        \n",
    "    else:\n",
    "        test_df.to_csv(test_save)\n",
    "    \n",
    "    \n",
    "    return train_save,test_save\n",
    "\n",
    "def most_probable_class(column_list):\n",
    "    col_val = set(column_list)\n",
    "    most_prob_class_count = 0\n",
    "    most_prob_class = 0\n",
    "    for ele in col_val:\n",
    "        class_count = column_list.count(ele)\n",
    "        if class_count > most_prob_class_count:\n",
    "            most_prob_class_count = class_count\n",
    "            most_prob_class = ele\n",
    "            \n",
    "    return most_prob_class\n",
    "\n",
    "\n",
    "def calc_baseline_acc(df_column_list):\n",
    "    \n",
    "    # Baseline accuracy is the accuracy when all the predicted classes are the most probable class\n",
    "    baseline_class = most_probable_class(df_column_list)\n",
    "    baseline_acc = df_column_list.count(baseline_class) / len(df_column_list) * 100\n",
    "    \n",
    "    print('Baseline accuracy:')\n",
    "    print(baseline_acc)\n",
    "    \n",
    "    return baseline_acc\n",
    "\n",
    "def acc(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "def sensitivity(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tp)/(tp+fn)\n",
    "\n",
    "def specificity(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tn)/(fp+tn)\n",
    "\n",
    "def tp_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return tp\n",
    "\n",
    "def fn_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # Needs the - sign since predictor.leaderboard flips the sign\n",
    "    return -fn  \n",
    "\n",
    "def fp_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # Needs the - sign since predictor.leaderboard flips the sign\n",
    "    return -fp  \n",
    "\n",
    "def tn_func(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return tn  \n",
    "\n",
    "\n",
    "def create_AutoGluon_extra_metrics(y_test,y_pred):\n",
    "    from autogluon.core.metrics import make_scorer\n",
    "    # Score functions need to have the definition:\n",
    "    # score_func(y, y_pred, **kwargs)\n",
    "    # Otherwise the calculations of the metrics will fail\n",
    "    \n",
    "    metrics_ls = []\n",
    "    metrics_ls.clear()\n",
    "    \n",
    "    # Calculate confusion matrix for custom metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    MCC = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "      \n",
    "    # Define custom scoring functions to pass to predictor.leaderboard()\n",
    "    ag_accuracy_scorer = make_scorer(name='Acc',\n",
    "                                 score_func=acc,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    ag_mcc_scorer = make_scorer(name='MCC',\n",
    "                                 score_func=matthews_corrcoef,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "    ag_sensitivity_scorer = make_scorer(name='SE',\n",
    "                                 score_func=sensitivity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "\n",
    "    ag_specificity_scorer = make_scorer(name='SP',\n",
    "                                 score_func=specificity,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)\n",
    "    \n",
    "  \n",
    "    tn_scorer = make_scorer(name='TN',score_func=tn_func,greater_is_better=True)\n",
    "\n",
    "    \n",
    "      \n",
    "    fp_scorer = make_scorer(name='FP',score_func=fp_func,greater_is_better=False)\n",
    "\n",
    "    \n",
    "      \n",
    "    fn_scorer = make_scorer(name='FN',score_func=fn_func,greater_is_better=False)\n",
    "\n",
    "    \n",
    "\n",
    "    tp_scorer = make_scorer(name='TP',score_func=tp_func,greater_is_better=True)\n",
    "\n",
    "    \n",
    "    # Append all metrics to list\n",
    "    metrics_ls.append(tp_scorer)\n",
    "    metrics_ls.extend((fp_scorer, fn_scorer, tn_scorer, ag_sensitivity_scorer,\n",
    "                      ag_specificity_scorer, ag_accuracy_scorer, ag_mcc_scorer))\n",
    "#     print(metrics_ls)\n",
    "    return metrics_ls\n",
    "#======================================================================================#\n",
    "def AutoGluon(training_set,test_set,save_path,model_results,model_name):\n",
    "    print('\\nSETTING UP DATA FOR MODEL...')\n",
    "    dat_train = pd.read_csv(training_set, sep=',')\n",
    "    dat_train_smi = dat_train['SMILES'].tolist()\n",
    "    print('\\ndat_train no. of SMILES:')\n",
    "    print(len(dat_train_smi))\n",
    "\n",
    "    y_train = dat_train[['Binary Activity']]\n",
    "    X_train,error_idx_ls = get_Morgan_fingerprint(dat_train_smi,2048,2)\n",
    "\n",
    "    y_train = y_train.drop(error_idx_ls)\n",
    "    X_train = X_train.drop(error_idx_ls)\n",
    "\n",
    "    dat_test = pd.read_csv(test_set, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    y_test = dat_test[['Binary Activity']]\n",
    "    X_test,error_idx_ls = get_Morgan_fingerprint(dat_test_smi,2048,2)\n",
    "\n",
    "    # Drop rows with errors\n",
    "    y_test = y_test.drop(error_idx_ls)\n",
    "    X_test = X_test.drop(error_idx_ls)\n",
    "\n",
    "    print(X_train)\n",
    "    print(y_train)\n",
    "\n",
    "    print('\\nDATA SET UP FOR MODEL')\n",
    "    \n",
    "    print('\\nPREPARING AND TRAINING MODELS...')\n",
    "    # The dataframes need to be converted to the object used byu the AutoGluon package\n",
    "    label = 'Binary Activity'\n",
    "    train_data = TabularDataset(pd.concat([X_train,y_train],axis=1))\n",
    "    \n",
    "    # This the maximum time limit in seconds for each set of models\n",
    "    # Essentially, this means the models will take an estimated (13 * time_limit * (num_stack_levels +1)) \n",
    "    # amount of seconds to train. Note training time is also affected by the preset quality\n",
    "    time_limit = 60 * 60\n",
    "    metric = 'accuracy'\n",
    "    \n",
    "    # Best quality focuses on acc but takes longer to run. For more details see the package documentation\n",
    "    preset = 'best_quality'\n",
    "    \n",
    "    # add hyperparameter_tune_kwargs if necessary\n",
    "#     num_trials = 25  # try at most n different hyperparameter configurations for each type of model\n",
    "#     search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "#     hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#         'num_trials': num_trials,\n",
    "#         'scheduler' : 'local',\n",
    "#         'searcher': search_strategy,\n",
    "#     }\n",
    "    \n",
    "    \n",
    "    # Model ensembling with stacking/bagging\n",
    "    # According to the documentation, \"beyond hyperparameter-tuning with a correctly-specified evaluation metric,\n",
    "    # two other methods to boost predictive performance are bagging and stack-ensembling. \n",
    "    # You’ll often see performance improve if you specify num_bag_folds = 5-10, \n",
    "    # num_stack_levels = 1-3 in the call to fit(), but this will increase training times and memory/disk usage.\"\n",
    "    # By default no hyperparameter optimisation is done ie. when hyperparameter_tune_kwargs is not specified\n",
    "    predictor = TabularPredictor(label, eval_metric=metric,path=model_name).fit(train_data,num_bag_folds=5, \n",
    "                                                                num_bag_sets=1, num_stack_levels=1, \n",
    "                                                                time_limit=time_limit,\n",
    "                                                                presets=preset\n",
    "#                                                                ,hyperparameter_tune_kwargs=hyperparameter_tune_kwargs\n",
    "                                                               )\n",
    "                                                               \n",
    "    print('\\nMODELS TRAINED')\n",
    "    \n",
    "    print('\\nEVALUATING MODELS...')\n",
    "    test_data = TabularDataset(pd.concat([X_test,y_test],axis=1))\n",
    "    y_test = test_data[label]  # values to predict\n",
    "    X_test = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "    X_test.head()\n",
    "    \n",
    "    y_pred = predictor.predict(X_test)\n",
    "    #print(\"Predictions:  \\n\", y_pred)\n",
    "    #perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n",
    "    \n",
    "    #print(\"TRUE VALUES:  \\n\", y_test)\n",
    "    y_test = y_test.tolist()\n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    add_metrics = create_AutoGluon_extra_metrics(y_test,y_pred)\n",
    "\n",
    "    results_df = predictor.leaderboard(test_data, silent=True,\n",
    "                                       extra_metrics=add_metrics\n",
    "                                      )\n",
    "    results_df.to_csv(model_results)\n",
    "    print(results_df)\n",
    "    print('\\nMODELS EVALUATED')   \n",
    "    \n",
    "    return\n",
    "\n",
    "def set_up_test_data(test_path):\n",
    "    print('\\nSETTING UP DATA FOR MODEL...')\n",
    "\n",
    "    dat_test = pd.read_csv(test_path, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    y_test = dat_test[['Binary Activity']]\n",
    "    X_test,error_idx_ls = get_Morgan_fingerprint(dat_test_smi,2048,2)\n",
    "\n",
    "    # Drop rows with errors\n",
    "    y_test = y_test.drop(error_idx_ls)\n",
    "    \n",
    "    X_test = X_test.drop(error_idx_ls)\n",
    "\n",
    "    print('\\nDATA SET UP FOR MODEL')\n",
    "    \n",
    "    return X_test,y_test\n",
    "    \n",
    "def set_up_interpreting_results(test_path,y_pred,run):\n",
    "    print('\\nSETTING UP RESULTS FOR INTERPRETATION...')\n",
    "\n",
    "    dat_test = pd.read_csv(test_path, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    interpret_df = dat_test[['SMILES']]\n",
    "    interpret_df = interpret_df.join(dat_test['Binary Activity'])\n",
    "    interpret_df['y_pred'] = y_pred\n",
    "\n",
    "    # Add columns determining which are misclassified\n",
    "    # False positives\n",
    "    FP_ls = []\n",
    "    FP_ls.clear()\n",
    "    \n",
    "    for x in range(0,len(interpret_df)):\n",
    "        if interpret_df.iloc[x]['Binary Activity'] == 0 and interpret_df.iloc[x]['y_pred'] == 1:\n",
    "            FP_ls.append(\"True\")\n",
    "        else:\n",
    "            FP_ls.append(\"False\")\n",
    "            \n",
    "    # False negatives\n",
    "    FN_ls = []\n",
    "    FN_ls.clear()\n",
    "    \n",
    "    for x in range(0,len(interpret_df)):\n",
    "        if interpret_df.iloc[x]['Binary Activity'] == 1 and interpret_df.iloc[x]['y_pred'] == 0:\n",
    "            FN_ls.append(\"True\")\n",
    "        else:\n",
    "            FN_ls.append(\"False\")    \n",
    "\n",
    "    interpret_df['False positive'] = FP_ls\n",
    "    interpret_df['False negative'] = FN_ls\n",
    "    \n",
    "    interpret_df['run_no'] = run\n",
    "            \n",
    "    print('\\nRESULTS SET UP FOR INTERPRETATION')\n",
    "    \n",
    "    return interpret_df\n",
    "\n",
    "def predict_new_chemicals(test_path):\n",
    "    print('\\nSETTING UP DATA FOR MODEL...')\n",
    "\n",
    "    dat_test = pd.read_csv(test_path, sep=',')\n",
    "    dat_test_smi = dat_test['SMILES'].tolist()\n",
    "    print('\\ndat_test no. of SMILES:')\n",
    "    print(len(dat_test_smi))\n",
    "\n",
    "    X_test,error_idx_ls = get_Morgan_fingerprint(dat_test_smi,2048,2)\n",
    "\n",
    "    # Drop rows with errors\n",
    "  \n",
    "    X_test = X_test.drop(error_idx_ls)\n",
    "\n",
    "    print('\\nDATA SET UP FOR MODEL')\n",
    "    \n",
    "    return X_test\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "# Set filepaths for functions\n",
    "\n",
    "# Filename of model to load'\n",
    "# model_root_desc = 'V2.0.1 Developmental toxicity'\n",
    "model_root_desc = 'V2.0.1 Reproductive toxicity'\n",
    "\n",
    "# Filepath of test csv containing two columsn 'SMILES' and 'Binary Activity'\n",
    "root = 'C:/Users/mwhw3/Desktop/DART project/'\n",
    "\n",
    "# Set number of runs to consider\n",
    "# For each run, there will be a set of trained models.\n",
    "# If only making a single prediction, just use any of the runs since model performance is rather consistent across all runs\n",
    "total_runs = 1\n",
    "\n",
    "# Set filepath for overall save if doing additional processing later\n",
    "# overall_save = root + 'AutoML models combined interpreting predicted results/' + model_root_desc + \\\n",
    "# str(total_runs) +' runs V2 interpreting predicted results.csv'\n",
    "#overall_save = root + 'AutoML models combined results/' + root_desc + ' ' + str(total_runs) +' runs.csv'\n",
    "\n",
    "#==============================================================================================#\n",
    "#==============================================================================================#\n",
    "\n",
    "\n",
    "for run in range(1,total_runs+1):\n",
    "    \n",
    "    print('\\n#=========================================================================================#')\n",
    "    print('#=========================================================================================#')\n",
    "    print('\\n                               NOW PERFORMING RUN {}\\n'.format(run))\n",
    "    print('#=========================================================================================#')\n",
    "    print('#=========================================================================================#')\n",
    "    \n",
    "    model_desc = model_root_desc + ' ' + str(run)\n",
    "    dataset_desc = model_desc +  ' CSV test.csv'\n",
    "\n",
    "    # Load location for models\n",
    "    model_name = root + 'AutoML models/' + model_desc + '/' + 'Models/'\n",
    "    print(model_name)\n",
    "\n",
    "    # Save location for model results if necessary\n",
    "#     check_path = root + 'Urgent chemicals/' + model_desc + '/'\n",
    "#     if os.path.exists(check_path)== False:\n",
    "#         os.makedirs(check_path)\n",
    "        \n",
    "#     model_results = root + 'AutoML models/' + model_desc + '/' + 'Interpreting Predicted Results/' + model_desc + ' interpreting predicted results.csv'\n",
    "#     interpret_df_save = root + 'AutoML models/' + model_desc + '/' + 'Interpreting Predicted Results/' + model_desc + ' V2 interpreting predicted results.csv'\n",
    "    \n",
    "    #==============================================================================================#\n",
    "    # Set up test data\n",
    "    test_path = root + 'Urgent chemicals/' + 'DART_chemicals.csv'\n",
    "    \n",
    "    # If test data has 'Binary Activity'\n",
    "#     X_test,y_test = set_up_test_data(test_path)\n",
    "\n",
    "#     test_data = TabularDataset(pd.concat([X_test,y_test],axis=1))\n",
    "#     y_test = y_test['Binary Activity'].tolist()\n",
    "    \n",
    "    # If test data does not have 'Binary Activity'\n",
    "    X_test = predict_new_chemicals(test_path)\n",
    "    #==============================================================================================#                             \n",
    "\n",
    "    # Load predictor   \n",
    "    predictor = TabularPredictor.load(model_name)\n",
    "    all_models = predictor.get_model_names()\n",
    "    #     print(all_models)\n",
    "    \n",
    "    # *** Set this manually ***\n",
    "    # Choose the models you want to use\n",
    "    # If not sure of the model name, refer to print(all_models)\n",
    "    if model_root_desc == 'V2.0.1 Developmental toxicity':\n",
    "        best_model = 'WeightedEnsemble_L2'\n",
    "    if model_root_desc == 'V2.0.1 Reproductive toxicity':\n",
    "        best_model = 'RandomForestGini_BAG_L2'\n",
    "    if model_root_desc == 'V2.0.1 Unified data':\n",
    "        best_model = 'ExtraTreesEntr_BAG_L2'\n",
    "    \n",
    "    ###\n",
    "    # If only using one model to predict\n",
    "    model_i = 0  # Set default index of model to use in set of models within predictor\n",
    "    i = 0\n",
    "    \n",
    "    model_i = [i for i,x in enumerate(all_models) if best_model == x]\n",
    "    model_i = model_i[0]\n",
    "    model_to_use = predictor.get_model_names()[model_i]\n",
    "    model_pred = predictor.predict(X_test, model=model_to_use)\n",
    "    print(\"\\nPredicting using %s model\" % (model_to_use))               \n",
    "    \n",
    "    y_pred = predictor.predict(X_test)\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    # Can save this df to csv if need be\n",
    "    y_pred_df = pd.DataFrame({'Result':y_pred})\n",
    "    print(y_pred_df)\n",
    "    \n",
    "    \n",
    "#     interpret_df = set_up_interpreting_results(test_path,y_pred,run)\n",
    "    \n",
    "#     # This is to create a set of metrics. Only do this if your new chemicals have known activities/toxicities\n",
    "#     add_metrics = create_AutoGluon_extra_metrics(y_test,y_pred)\n",
    "#     results_df = predictor.leaderboard(test_data, silent=True,\n",
    "#                                        extra_metrics=add_metrics\n",
    "#                                       )      \n",
    "    #results_df.to_csv(model_results)\n",
    "    \n",
    "    \n",
    "#     interpret_df.to_csv(interpret_df_save)\n",
    "#     print(results_df)\n",
    "#     print(interpret_df)\n",
    "\n",
    "\n",
    "    ###\n",
    "#     # If using multiple models to predict ie. check prediction of ensemble of models\n",
    "\n",
    "#     # This gets the models (names) of all the models used\n",
    "#     all_models = predictor.get_model_names()\n",
    "\n",
    "#     count = 0\n",
    "#     for use_model in all_models:\n",
    "#         y_pred = predictor.predict(X_test, model=use_model)\n",
    "#         y_pred = y_pred.tolist()\n",
    "#         if count == 0:\n",
    "#             interpret_df = set_up_interpreting_results(test_path,y_pred,run)\n",
    "#             combined_df = interpret_df\n",
    "#             combined_df['Model'] = str(use_model)\n",
    "#             count = count + 1\n",
    "#             print(combined_df)\n",
    "#         else:\n",
    "#             interpret_df = set_up_interpreting_results(test_path,y_pred,run)\n",
    "#             interpret_df['Model'] = str(use_model)\n",
    "#             combined_df = combined_df.merge(interpret_df, how='inner', on='SMILES')\n",
    "#             print(combined_df)\n",
    "#             count = count + 1\n",
    "#             if count == len(all_models):\n",
    "#                 combined_df_save = root + 'AutoML models combined interpreting predicted results/' +  model_desc + ' V2 misclassified predicted results.csv'\n",
    "#                 combined_df.to_csv(combined_df_save)\n",
    "\n",
    "    print('\\nMODELS EVALUATED')\n",
    "    \n",
    "    \n",
    "print('\\n#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('\\n                         ALL MODELS EVALUATED\\n'                          )\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "print('#=========================================================================================#')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaee2ae",
   "metadata": {},
   "source": [
    "# For getting the \"nearest neighbours\" of the chemicals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739db48",
   "metadata": {},
   "source": [
    "This would get the most similar chemicals in the training set for the chemicals in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48114c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For calculating the average similarity per molecule for the 5 nearest neighbours in both the training and the test sets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdDepictor\n",
    "\n",
    "from rdkit import DataStructs\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "#===================================================================================#\n",
    "def get_Morgan_fingerprint(smiles,nBits,fingerprint_radius):\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol,fingerprint_radius,nBits=nBits)\n",
    "    \n",
    "    return fp\n",
    "\n",
    "\n",
    "#==============================================================================================#\n",
    "def calc_Tanimoto_similarity(smiles1,smiles2):\n",
    "    fp1 = get_Morgan_fingerprint(smiles1,2048,2)\n",
    "    fp2 = get_Morgan_fingerprint(smiles2,2048,2)\n",
    "    similarity = DataStructs.FingerprintSimilarity(fp1,fp2,metric=DataStructs.TanimotoSimilarity)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "#===================================================================================#\n",
    "# Set filenames for required data\n",
    "# Ensure that you model_root_desc and the training data are for the same toxicity\n",
    "total_runs = 1\n",
    "root = 'C:/Users/mwhw3/Desktop/DART project/'\n",
    "# model_root_desc = 'V2.0.1 Developmental toxicity'\n",
    "model_root_desc = 'V2.0.1 Reproductive toxicity'\n",
    "model_desc = model_root_desc + ' ' + str(total_runs)\n",
    "\n",
    "# Input df. This contains the chemicals for which you want to find the most similar compounds for.\n",
    "input_filename = root + 'Urgent chemicals/' +   \\\n",
    "'DART_chemicals.csv'\n",
    "\n",
    "# Load model training data to calculate similarties with training set\n",
    "# training_input_filename = root + 'AutoML models/' +  model_desc + \\\n",
    "# '/Data/V2.0.1 Developmental toxicity 1 CSV train.csv'\n",
    "training_input_filename = root + 'AutoML models/' +  model_desc + \\\n",
    "'/Data/V2.0.1 Reproductive toxicity 1 CSV train.csv'\n",
    "\n",
    "\n",
    "# kmeans_analysis_input = root + 'Feature plots/kmeans/' +  model_desc + ' V2 all K-means PCA misclassifion analysis.csv'\n",
    "\n",
    "# final_analysis_save = root + 'Similarities/' +  model_desc + \\\n",
    "# ' V2 training and test similarity pair analysis.csv'\n",
    "\n",
    "# merged_df_save = root + 'Similarities/' +  model_desc + \\\n",
    "# ' V2 merged training and test similarity pair analysis.csv'\n",
    "\n",
    "# # Sometimes csv saves but columns load incorrectly when opening with excel\n",
    "# # This mitigates the issue entierly by directly saving as xlsx\n",
    "# merged_df_save_xlsx = root + 'Similarities/' +  model_desc + \\\n",
    "# ' V2 merged training and test similarity pair analysis.xlsx'\n",
    "#===================================================================================#\n",
    "\n",
    "initial_df = pd.read_csv(input_filename)\n",
    "\n",
    "try:\n",
    "    initial_df = initial_df[initial_df.columns.drop(list(initial_df.filter(regex='Unnamed')))]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "training_df = pd.read_csv(training_input_filename)\n",
    "\n",
    "try:\n",
    "    training_df = training_df[training_df.columns.drop(list(training_df.filter(regex='Unnamed')))]\n",
    "except:\n",
    "    pass\n",
    "print('TRAINING DF\\n')\n",
    "print(training_df)\n",
    "\n",
    "input_df = initial_df\n",
    "test_smiles_df = input_df[['SMILES']]\n",
    "training_smiles_df = training_df[['SMILES']]\n",
    "print('INPUT DF\\n')\n",
    "print(input_df)\n",
    "\n",
    "#===================================================================================#\n",
    "# Get list of Tanimoto similarities per molecule in the dataset\n",
    "smiles_df_ls = []\n",
    "\n",
    "for x in range(0,len(test_smiles_df)):\n",
    "    \n",
    "    # If calculating between training and test set\n",
    "    copy_df = training_smiles_df.copy()    \n",
    "    \n",
    "    # If calculating within test set\n",
    "#     copy_df = test_smiles_df.copy()\n",
    "#     copy_df = copy_df.drop([x], axis=0)\n",
    "    \n",
    "    # Calculate list of Tanimoto similarities\n",
    "    # Note that this calculates for all similarity pairs so expect major time consumption here if running for\n",
    "    # a large number of chemicals\n",
    "    similarity_ls = []\n",
    "    smiles1 = test_smiles_df.loc[x]['SMILES']\n",
    "#     smiles1 = training_smiles_df.loc[x]['SMILES']\n",
    "    for index, row in copy_df.iterrows():\n",
    "        smiles2 = row['SMILES']\n",
    "        similarity_ls.append(calc_Tanimoto_similarity(smiles1,smiles2))\n",
    "        if len(similarity_ls) % 150 == 0 and x % 100 == 0:\n",
    "            print('\\nNOW PROCESSING INDEX {} IN COPY_DF FOR MOLECULE {}'.format(index,x))\n",
    "            print(len(similarity_ls),'SIMILARITY PAIRS CALCULATED')\n",
    "    smiles_df_ls.append(similarity_ls)\n",
    "        \n",
    "final_analysis_df = input_df.copy()\n",
    "# final_analysis_df = training_smiles_df.copy()\n",
    "final_analysis_df['similarity'] = smiles_df_ls\n",
    "final_analysis_df = final_analysis_df[['SMILES','similarity']]\n",
    "\n",
    "# Get average similarity and average of top 1,3,5 similarity per compound\n",
    "average_sim = []\n",
    "top_1 = []\n",
    "top_3 = []\n",
    "top_5 = []\n",
    "\n",
    "for index, row in final_analysis_df.iterrows():\n",
    "    to_process = row['similarity']\n",
    "    to_process = sorted(to_process, reverse=True)\n",
    "    \n",
    "    average_sim.append(mean(to_process))\n",
    "    top_1.append(to_process[0])\n",
    "    top_3.append(mean(to_process[0:3]))\n",
    "    top_5.append(mean(to_process[0:5]))\n",
    "    \n",
    "    \n",
    "final_analysis_df['average_sim'] = average_sim\n",
    "final_analysis_df['top_1'] = top_1\n",
    "final_analysis_df['top_3'] = top_3\n",
    "final_analysis_df['top_5'] = top_5\n",
    "\n",
    "print(final_analysis_df)\n",
    "# final_analysis_df.to_csv(final_analysis_save)\n",
    "\n",
    "print('\\nFINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f56ee9",
   "metadata": {},
   "source": [
    "# Process final_analysis_df if doing train test pairs to get top n similar structures in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69299886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continued from previous cell. Set filenames\n",
    "# Save to excel. Sometimes the csv will not load correctly so saving to excel prevents this issue.\n",
    "sim_df_save_xlsx = root + 'Urgent chemicals/' +  model_desc + \\\n",
    "' similarity results.xlsx'\n",
    "\n",
    "#===================================================================================================#\n",
    "\n",
    "sim_df = final_analysis_df\n",
    "\n",
    "# merged_smiles_ls = input_df['SMILES']\n",
    "sim_smiles_ls = training_df['SMILES']\n",
    "print(len(sim_smiles_ls))\n",
    "sorted_SMILES = []\n",
    "sorted_similarity = []\n",
    "for index,row in final_analysis_df.iterrows():\n",
    "    to_sort = row['similarity']\n",
    "#     print(to_sort)\n",
    "    # Get top 5 indices and values for similarity pairs\n",
    "    # Change the right hand number if you require more than top 5 pairs\n",
    "    sorted_tuple = sorted(enumerate(to_sort), reverse=True, key=lambda x: x[1])[:5]\n",
    "#     print(sorted_tuple)\n",
    "    indices,value = [list(ele) for ele in zip(*sorted_tuple)]\n",
    "#     index = [index for index, value in sorted(enumerate(to_sort), reverse=True, key=lambda x: x[1])[:6]\n",
    "             \n",
    "    # Get corresponding SMILES as list\n",
    "#     print(indices)\n",
    "#     print(value)\n",
    "    temp = [sim_smiles_ls[i] for i in indices]  \n",
    "    sorted_SMILES.append(temp)\n",
    "    sorted_similarity.append(value)\n",
    "    \n",
    "final_analysis_df['sorted_SMILES'] = sorted_SMILES\n",
    "final_analysis_df['sorted_similarity'] = sorted_similarity\n",
    "                   \n",
    "print('\\nDF PROCESSED')\n",
    "print(sim_df)\n",
    "sim_df.to_excel(sim_df_save_xlsx, index=True)\n",
    "\n",
    "print('\\nFINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3bbe95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
